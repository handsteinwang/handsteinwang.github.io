{"posts":[{"title":"Analogy between Sampling and Optimization","text":"This is the talk I presented in the group seminar, titled: Analogy between Sampling and Optimization. Click here to download the slides. The cover image of this article was taken on the Royal Caribbean cruise to Kagoshima, Japan.","link":"/2025/09/26/Analogy_between_Sampling_and_Optimization/"},{"title":"Reversible, Conductance and Rapid Mixing of Markov Chains","text":"IntroductionMarkov ChainLet $(\\Omega,\\mathcal{F})$ be a measurable space, $P:\\Omega\\times \\mathcal{F}\\to [0,1]$ be a transition kernel, that is, for every $x\\in \\Omega$, $P(x,\\cdot)$ is a probability measure on $\\mathcal{F}$; for every $A\\in \\mathcal{F}$, $x\\mapsto P(x,A)$ is measurable. And we say the triple $(\\Omega,\\mathcal F,P)$ is a Markov scheme. Fix an initial distribution $\\mu_0$ on $(\\Omega,\\mathcal F)$. By the Kolmogorov consistency theorem, there exists a unique probability measure $\\mathbb{P}$ on the product space $(\\Omega^{\\mathbb N_0},\\mathcal F^{\\otimes\\mathbb N_0})$ such that for the coordinate process $\\{X_k\\}$,$$\\mathbb P(X_0\\in A_0,\\dots,X_n\\in A_n)=\\int_{A_0}\\mu_0(dx_0)\\int_{A_1}P(x_0,dx_1)\\cdots\\int_{A_n}P(x_{n-1},dx_n),\\qquad A_0,\\dots,A_n\\in\\mathcal F.$$ Equivalently: $X_0\\sim\\mu_0$; for every $k\\ge 0$ and $A\\in\\mathcal F$, $$\\mathbb P(X_{k+1}\\in A\\mid X_0,\\dots,X_k)=\\mathbb P(X_{k+1}\\in A\\mid X_k)\\quad \\text{a.s.} \\qquad \\text{(Markov property)}.$$ In this case, the coordinate process $(X_k)_{k\\ge 0}$ (and, more generally, any process with the same finite-dimensionaldistributions) is called a Markov chain with initial distribution $\\mu_0$ and transition kernel $P$. Invariant MeasureDefinition: A probability measure $\\pi$ on $(\\Omega,\\mathcal F)$ is invariant (stationary) for $P$ if$$(\\pi P)(A):=\\int_\\Omega \\pi(dx)\\ P(x,A) =\\pi(A).$$Equivalently, if $X_0\\sim\\pi$, then $X_k\\sim\\pi$ for every $k\\ge 1.$ Markov OperatorConsider the Hilbert space $L^2=L^2(\\Omega,\\mathcal{F},\\pi)$ with the inner product$$\\langle f,g\\rangle_\\pi:=\\int_\\Omega f\\ g\\ d\\pi.$$Every Markov scheme defines a positive linear operator $M:L^2\\to L^2$ by$$(Mf)(x) := \\int_\\Omega f(y)\\ P(x, dy).$$ ReversibilityRoughly speaking, a Markov scheme is reversible if for any two sets $A,B\\in \\mathcal{F}$, it steps from $A$ to $B$ as often as from $B$ to $A$. Definition: A Markov scheme is reversible with respect to probability measure $\\pi$ if$$\\pi(dx)P(x,dy) = \\pi(dy)P(y,dx),\\quad x,y\\in \\Omega$$Lemma 1: The followings are equivalent: (1) Markov scheme is reversible with respect to probability measure $\\pi$; (2) for any two sets $A,B\\in \\mathcal{F}$,$$\\int_B \\pi(dx)P(x,A) = \\int_A\\pi(dx)P(x,B);$$(3) for any measurable function $F:\\Omega\\times \\Omega \\to\\mathbb{R}$ that makes the integral below finite, we have$$\\int_\\Omega\\int_\\Omega F(x,y)\\ \\pi(dx)P(x,dy) = \\int_\\Omega\\int_\\Omega F(y,x)\\ \\pi(dx)P(x,dy);$$(4) the Markov operator $M$ is self-adjoint. Proof: $(1)\\Longrightarrow (2):$ for any two sets $A,B\\in \\mathcal{F}$,$$\\int_B \\pi(dx)P(x,A) = \\int_B \\pi(dx)\\int_A P(x,dy)\\xlongequal{\\text{Fubini}} \\int_A\\int_B \\pi(dx)P(x,dy)\\xlongequal{(1)} \\int_A\\int_B \\pi(dy)P(y,dx)\\xlongequal{\\text{Fubini}}\\int_A\\pi(dy)\\int_B P(y,dx)=\\int_A\\pi(dy)P(y,B)= \\int_A\\pi(dx)P(x,B);$$$(2)\\Longrightarrow (3):$ it is easy to show that (3) holds for indicator functions $F(x,y)=1_A(x)1_B(y)$ and then (3) holds for any bounded measurable function $F:\\Omega\\times \\Omega \\to\\mathbb{R}$ by just using the Monotone Class Theorem. $(3)\\Longrightarrow (4):$ For $f,g$ in $L^2$,$$\\langle f,Mg\\rangle_\\pi=\\int_\\Omega f(x)\\ (Mg)(x)\\ \\pi(dx) = \\int_\\Omega f(x)\\int_\\Omega g(y)\\ P(x, dy)\\ \\pi(dx) \\xlongequal{\\text{Fubini}}\\int_\\Omega\\int_\\Omega f(x)g(y)\\ \\pi(dx)P(x,dy)$$ $$\\langle Mf,g\\rangle_\\pi= \\int_\\Omega (Mf)(x)\\ g(x)\\ \\pi(dx)= \\int_\\Omega g(x)\\int_\\Omega f(y)\\ P(x, dy)\\ \\pi(dx)\\xlongequal{\\text{Fubini}}\\int_\\Omega\\int_\\Omega f(y)g(x)\\ \\pi(dx)P(x,dy)$$ By using (3) with $F(x,y)=f(x)g(y)$, we obtain $\\langle f,Mg\\rangle_\\pi=\\langle Mf,g\\rangle_\\pi$ directly. $(4)\\Longrightarrow (1):$ Let $f=1_A$ and $g=1_B$, the desired result follows directly by the above equations. Lemma 2: If the Markov scheme is reversible with respect to probability measure $\\pi$, then for any $f\\in L^2$,$$|\\langle f,Mf\\rangle_\\pi|\\le \\langle f,f\\rangle_\\pi,$$and the equation holds when $f$ is a constant function. Thus the spectral radius of $M$ is exactly $1$. Proof: For any $f\\in L^2$, applying Lemma 1(3) with $F(x,y)=f(x)$, it is easy to show that$$\\langle f,f\\rangle_\\pi\\ \\pm\\ \\langle f,Mf\\rangle_\\pi=\\frac{1}{2}\\int_\\Omega\\int_\\Omega (f(x)\\pm f(y))^2\\ \\pi(dy)P(y,dx)\\ge 0.$$And then the desired result follows. Lemma 3: If the Markov scheme is reversible with respect to probability measure $\\pi$, then $\\pi$ is an invariant measure of the Markov scheme. Proof: For all $A\\in\\mathcal{F}$,$$(\\pi P)(A)=\\int_\\Omega \\pi(dx)\\ P(x,A)=\\int_\\Omega \\pi(dx)\\ \\int_A P(x,dy)\\xlongequal{\\text{Fubini}}\\int_\\Omega \\int_\\Omega 1_A(y)\\pi(dx)P(x,dy)\\xlongequal{\\text{Lemma 1(3)}}\\int_\\Omega \\int_\\Omega 1_A(x)\\pi(dx)P(x,dy)=\\pi(A).$$ Laziness of Markov ChainsDefinition: We call the Markov scheme lazy if$$P(x,\\{x\\})\\ge \\frac12\\qquad\\text{for all }x\\in\\Omega.$$(Informally: with probability at least $1/2$ the chain stays put.) Lemma 4: If the Markov scheme is lazy and reversible, then $M$ is positive semi-definite. Proof: Consider the operator $2M-I$, which corresponds to the kernel$$\\widetilde P(x,A):=2P(x,A)-\\mathbf 1_A(x).$$Laziness ensures $\\widetilde P(x,\\cdot)$ is still a probability measure (nonnegativity at $\\{x\\}$ is exactly $2P(x,\\{x\\})-1\\ge 0$), hence $2M-I$ is again a Markov operator and is self-adjoint. And then by Lemma 2,$$\\langle f,Mf\\rangle_\\pi=\\frac12\\langle f,f\\rangle_\\pi+\\frac12\\langle f,(2M-I)f\\rangle_\\pi\\ge \\frac12\\langle f,f\\rangle_\\pi-\\frac12\\langle f,f\\rangle_\\pi=0.$$And then the desired result follows. Note: Every Markov scheme can be made lazy by simply tossing a coin at each step and making a move only if it is tails. So (at the cost of a little slow-down) we can assume that $M$ is positive semi-definite, which will be very convenient. Ergodic FlowDefinition: ** We define the **ergodic flow $\\Phi: \\mathcal{F}\\to[0,1]$ of the Markov scheme by$$\\Phi(A) = \\int_A P(x,A^c)\\pi(dx),$$which is the probability of the event that in choosing $X_0$ from the invariant distribution we have $X_0\\in A$ but $X_1\\notin A$. Lemma 5: For all $A\\in \\mathcal{F}$, we have $\\Phi(A)=\\Phi(A^c)$. *Proof: * For all $A\\in \\mathcal{F}$, from the assumption that $\\pi$ is invariant, we get$$\\Phi(A)-\\Phi(A^c) = \\int_{A} P(x,A^c)\\pi(dx)-\\int_{A^c} P(x,A)\\pi(dx)=\\int_{A} (1-P(x,A))\\pi(dx)-\\int_{A^c} P(x,A)\\pi(dx)=\\pi(A)-\\int_\\Omega P(x,A)\\pi(dx) = 0.$$And then the desired result follows. Note that the computation also works backward, we have the following lemma. Lemma 6: If $\\nu$ is any probability measure on $(\\Omega,\\mathcal{F})$ such that the set-function$$\\Psi(A) =\\int_A P(x,A^c)\\nu(dx)$$is invariant under complementation, namely, $\\Psi(A)=\\Psi(A^c)$, then $\\nu$ is invariant. *Proof: * For all $A\\in \\mathcal{F}$, from the assumption that $\\Psi(A)=\\Psi(A^c)$, we have$$0=\\Psi(A)-\\Psi(A^c)=\\int_{A} P(x,A^c)\\nu(dx)-\\int_{A^c} P(x,A)\\nu(dx)=\\int_{A} (1-P(x,A))\\nu(dx)-\\int_{A^c} P(x,A)\\nu(dx)=\\nu(A)-\\int_\\Omega P(x,A)\\nu(dx),$$which means $\\nu P=\\nu$, $\\nu$ is invariant. ConductanceDefinition: *The *conductance of the Markov scheme is$$\\Phi:=\\inf_{0&lt;\\pi(A)&lt;1/2} \\frac{\\Phi(A)}{\\pi(A)}.$$For every $0\\le s\\le 1$, the $s-$conductance is defined by$$\\Phi_s:=\\inf_{s&lt;\\pi(A)&lt;1/2} \\frac{\\Phi(A)}{\\pi(A)-s}.$$And we call the value $1-P(x,\\{x\\})$ the local conductance of the Markov scheme at element $x$. Lemma 7: If the invariant measure $\\pi$ has an atom $y$ (i.e. $\\pi(\\{y\\})&gt;0$), then the local conductance of the Markov scheme at element $y$ is just $\\Phi(\\{y\\})/\\pi(\\{y\\})$, hence$$\\Phi\\le \\frac{\\Phi(\\{y\\})}{\\pi(\\{y\\})} =1-P(y,\\{y\\}).$$*Proof: *$$\\Phi(\\{y\\})= \\int_{\\{y\\}} P(x,\\{y\\}^c)\\pi(dx)=P(\\{y\\},\\{y\\}^c)\\pi(\\{y\\})= (1-P(y,\\{y\\}))\\pi(\\{y\\})$$Since $\\pi(\\{y\\})&gt;0$, we get the desired result. Lemma 8: Let$$H_t=\\{x\\in\\Omega; 1-P(x,\\{x\\})&lt;t\\},$$and $s=\\pi(H_t)$. Then$$\\Phi(H_t)&lt;t\\ \\pi(H_t).$$As a consequence, if $s&lt;1/2$, then the $(s/2)-$conductance of the Markov scheme is at most $2t$.*Proof: *$$\\Phi(H_t)=\\int_{H_t} P(x,H_t^c)\\pi(dx)&lt;\\int_{H_t} P(x,\\{x\\}^c)\\pi(dx)&lt;t\\ \\pi(H_t)=ts.$$If $s&lt;1/2$, then$$\\Phi_{s/2}= \\inf_{s/2&lt;\\pi(A)&lt;1/2} \\frac{\\Phi(A)}{\\pi(A)-s/2}\\le \\frac{\\Phi(H_t)}{\\pi(H_t)-s/2}&lt; \\frac{ts}{s-s/2}=2t.$$ Mixing TimeLet $\\mu_k$ denotes the law of $X_k$. By definition, we have the recurrence$$\\mu_k(A)=\\int_\\Omega \\mu_{k-1}(dx)P(x,A)$$The reason for us to introduce the definition of conductance is that if the conductance $\\Phi&gt;0$, then$$\\operatorname{TV}(\\mu_k,\\pi):=\\sup_{A\\in\\mathcal{F}}|\\mu_k(A)-\\pi(A)|\\to 0 \\quad \\text{as }k\\to \\infty.$$We have the following theoerms. Theorem 1: Let$$M=\\sup_{A\\in \\mathcal{F}} \\frac{\\mu_0(A)}{\\pi(A)}\\tag{warm-start}.$$Then$$\\operatorname{TV}(\\mu_k,\\pi):=\\sup_{A\\in\\mathcal{F}}|\\mu_k(A)-\\pi(A)|\\le \\sqrt{M}\\left(1-\\frac{1}{2}\\Phi^2\\right)^k$$Theorem 2: Let $0&lt;s\\le 1/2$ and $H_s=\\sup\\{|\\mu_0(A)-\\pi(A)|; \\pi(A)\\le s\\}$. Assume that each atom has $\\pi-$measure less than $1/2$, then$$\\operatorname{TV}(\\mu_k,\\pi):=\\sup_{A\\in\\mathcal{F}}|\\mu_k(A)-\\pi(A)|\\le 2H_s+\\frac{2H_s}{s}\\left(1-\\frac{1}{2}\\Phi_s^2\\right)^k$$Furthermore, if $\\pi$ is atom-free, then$$\\operatorname{TV}(\\mu_k,\\pi):=\\sup_{A\\in\\mathcal{F}}|\\mu_k(A)-\\pi(A)|\\le H_s+\\frac{H_s}{s}\\left(1-\\frac{1}{2}\\Phi_s^2\\right)^k$$ See [1] for the proofs of Theorems 1 and 2. Definition: The mixing time in total variation distance is defined by$$t_{\\text{TV}}(\\varepsilon,\\mu_0):=\\inf\\{k\\in \\mathbb{N}| \\operatorname{TV}(\\mu_k,\\pi)\\le \\varepsilon\\}$$ Relation to Sampling AlgorithmsIn non-asymptotic analysis of the convergence of sampling algorithms, mixing time plays a central role. In much of the literature on sampling algorithms, it is common to assume warm start for the initial distribution. Definition: ** We say that the initial distribution $\\mu_0$ is **$M-$warm, if it satisfies$$\\sup_{A\\in \\mathcal{F}} \\frac{\\mu_0(A)}{\\pi(A)}\\le M$$Under $M-$warm assumption, and if target distribution is atom-free, then $H_s$ defined in Theorem 2 above satisfies$$H_s=\\sup\\{|\\mu_0(A)-\\pi(A)|; \\pi(A)\\le s\\}\\le \\min\\{s,(M-1)s\\}\\le Ms.$$Then by Theorem 2, we get$$\\operatorname{TV}(\\mu_k,\\pi)\\le Ms+ M\\left(1-\\frac{1}{2}\\Phi_s^2\\right)^k\\le Ms+ Me^{-\\frac{n}{2}\\Phi_s^2}.$$Then $\\operatorname{TV}(\\mu_k,\\pi)\\le \\varepsilon$ follows from taking$$s=\\frac{\\varepsilon}{2M},\\quad k\\ge \\frac{2}{\\Phi_s^2}\\log\\frac{2M}{\\varepsilon}.$$Hence, the problem of analyzing the mixing time is reduced to controlling the $s-$conductance $\\Phi_s$. Reference[1] Lovász, László, and Miklós Simonovits. “Random walks in a convex body and an improved volume algorithm.” Random structures &amp; algorithms 4.4 (1993): 359-412.","link":"/2025/12/18/Markov_Chain_1/"},{"title":"Introduction to Gamma Convergence","text":"MotivationLet $(X,d)$ be a metric space, $F, F_n: X\\to \\overline{\\mathbb{R}}, n=1,2,\\cdots$ be functionals, suppose that $x_n\\in X$ minimizes $F_n$ for each $n=1,2,\\cdots$, does $\\lim\\limits_{n\\to\\infty} x_n$ (if it exists) minimize any functional $F$? And in what sense does $F_n$ converge to $F$ ensure the minimizer of $F_n$ converges to minimizer of $F$? Example 1. Let $ H_0^1((0,1);\\mathbb{R})=\\{u:(0,1)\\to \\mathbb{R}| u\\in L^2,\\nabla u\\in L^2, u(0)=u(1)=0\\} $ and functional $F: H_0^1((0,1);\\mathbb{R})\\to [0,+\\infty]$ be defined via$$F(u):= \\int_0^1 (u^\\prime(x)^2-1)^2 dx.$$Define$$F_n(u):=\\begin{cases}F(u),&amp; \\text{if } u^\\prime \\text{ is constant on } (\\frac{i}{2n},\\frac{i+1}{2n}), i=0,1,\\cdots,2n-1\\\\\\+\\infty,&amp; \\text{otherwise}\\end{cases}$$and let $u_n$ be a minimizer of $F_n$ defined by$$u_1(x)=\\begin{cases}x,&amp; x\\in [0,\\frac{1}{2})\\\\\\1-x,&amp; x\\in [\\frac{1}{2},1]\\end{cases}, \\quad u_2(x)=\\begin{cases}x,&amp; x\\in [0,\\frac{1}{4})\\\\\\\\frac{1}{2}-x&amp; x\\in [\\frac{1}{4},\\frac{1}{2})\\\\\\x-\\frac{1}{2}&amp; x\\in [\\frac{1}{2},\\frac{3}{4})\\\\\\1-x,&amp; x\\in [\\frac{3}{4},1]\\end{cases},\\quad \\cdots$$ It is easy to see that$$F_n(u_n)=0,\\quad \\forall n=1,2,\\cdots,$$and $u_n\\to u\\equiv 0$, but$$F(u)=1&gt;0,$$which shows that the pointwise limit $u$ is not the minimizer of $F$. Hence, we need to find a new type of convergence to answer the above question, which motivates the definition of $\\Gamma-$convergence. $\\Gamma$-convergenceDefinition 1. We say that a sequence of functionals $F_n:X\\to \\mathbb{R}\\ \\Gamma-$converges to $F:X\\to \\mathbb{R}$, denoted by $F_n\\xrightarrow{\\Gamma} F$, if for all $x\\in X$, we have (i) (liminf inequality) for all $(x_n)$ converging to $x$,$$F(x)\\le \\liminf_{n\\to\\infty} F_n(x_n).$$(ii) (limsup inequality) there exists $(x_n)$ converging to $x$ such that$$F(x)\\ge \\limsup_{n\\to\\infty}F_n(x_n).$$And we say the sequence $(x_n)$ in (ii) the recovery sequence. Example 2. Let $X=\\mathbb{R}$ and $F_n(x)=\\cos(nx)$, then $F_n\\xrightarrow{\\Gamma} F\\equiv -1$. Proposition 1. If $F_n\\xrightarrow{\\Gamma} F$ and $G$ is $d-$continuous, then $F_n+G\\xrightarrow{\\Gamma} F+G$. Proof: We first prove (i). For all $(x_n)$ converging to $x$, by $F_n\\xrightarrow{\\Gamma} F$, we have$$F(x)\\le \\liminf_{n\\to\\infty} F_n(x_n),$$then$$F(x)+G(x)\\le \\liminf_{n\\to\\infty} F_n(x_n)+\\lim_{n\\to\\infty} G(x_n)=\\liminf_{n\\to\\infty} (F_n(x_n)+G(x_n))$$Then we prove (ii). Suppose $(x_n)$ converging to $x$ such that$$F(x)\\ge \\limsup_{n\\to\\infty}F_n(x_n),$$then$$F(x)+G(x)\\ge \\limsup_{n\\to\\infty}F_n(x_n)+\\lim_{n\\to\\infty} G(x_n)=\\limsup_{n\\to\\infty} (F_n(x_n)+G(x_n)).$$Hence, by the definition of $\\Gamma-$convergence, $F_n+G\\xrightarrow{\\Gamma} F+G$. Example 3 ($\\Gamma-$limit of a constant sequence may not be itself). Consider $F_n\\equiv F$ and let $\\overline{F}$ be the $\\Gamma-$limit of $F_n$, by liminf inequality, we have for all $x\\in X$ and $x_n\\to x$,$$\\overline{F}(x)\\le \\liminf_{n\\to\\infty} F(x_n).$$Notice that if $F$ is not lower semi-continuous, then there exists $\\overline{x}\\in X$ and $\\overline{x}_n\\to \\overline{x}$ such that $$\\liminf_{n\\to\\infty} F(\\overline{x}_n) \\lt F(\\overline{x}).$$ Hence,$$\\overline{F}(\\overline{x})\\lt F(\\overline{x}),$$which shows that if $F$ is not lower semi-continuous, then $F$ is not the $\\Gamma-$limit. Proposition 2. If $F_n\\xrightarrow{\\Gamma} F$ and $F_n\\xrightarrow{pointwise} G$, then $F\\le G$. Proof: By definition, we take $x_n\\equiv x$ and then$$F(x)\\le \\liminf_{n\\to\\infty}F_n(x)=G(x).$$ Proposition 3. If $F_n$ uniformly converge to $F$ and $F$ is lower semi-continuous, then $F_n\\xrightarrow{\\Gamma} F$. Proof: We first prove (i), for all $(x_n)$ converging to $x$,$$\\liminf_{n\\to\\infty} F_n(x_n)=\\liminf_{n\\to\\infty} (F_n(x_n)-F(x_n)+F(x_n))=\\liminf_{n\\to\\infty} (F_n(x_n)-F(x_n))+\\liminf_{n\\to\\infty} F(x_n)\\ge F(x),$$where the last inequality is because the uniform convergence and lower semi-continuity. Next, we prove (ii), take $x_n\\equiv x$, we have$$\\limsup_{n\\to\\infty} F_n(x)=\\limsup_{n\\to\\infty} (F_n(x)-F(x)+F(x))=\\limsup_{n\\to\\infty} (F_n(x)-F(x))+ F(x)= F(x).$$ Convergence of MinimizerProposition 4. Let $F_n,F:X\\to\\overline{\\mathbb{R}}$, then (1) if liminf inequality is satisfied, then for all $x\\in X$ and $K\\subset X$ compact, we have$$\\inf_K F\\le \\liminf_{n\\to\\infty} \\inf_K F_n\\ ;$$(2) if limsup inequality is satisfied, then for all $x\\in X$ and $U\\subset X$ open, we have$$\\inf_K F\\ge \\limsup_{n\\to\\infty} \\inf_U F_n\\ .$$Proof: (1) By the definition of infimum, we can take $(\\tilde{x}_n)\\subset K$, such that $$\\liminf_{n\\to\\infty} \\inf_K F_n=\\liminf_{n\\to\\infty} F_n(\\tilde{x}_n)$$ Because $K$ is compact, up to extraction, we obtain $\\tilde{x}_{n_j}$ such that $$\\tilde{x}_{n_j}\\to\\tilde{x}\\in K$$ and $$\\liminf_{n\\to\\infty} \\inf_K F_n=\\lim_{j\\to\\infty} F_{n_j} (\\tilde{x}_{n_j})$$ By the liminf inequality, we obtain$$\\inf_K F\\le F(\\tilde{x})\\le \\lim_{j\\to\\infty}{ F_{n_j} (\\tilde{x}_{n_j})}$$ Hence$$\\inf_K F\\le F(\\tilde{x})\\le \\liminf_{n\\to\\infty} \\inf_K F_n$$(2) For all $\\delta&gt;0$, let $(x_n)$ be a recovery sequence for $x\\in U$ such that$$F(x)\\le \\inf_U F+\\delta.$$Hence by limsup inequality$$\\inf_U F+\\delta \\ge F(x)\\ge \\limsup_{n\\to\\infty} F_n(x_n)\\ge \\limsup_{n\\to\\infty} \\inf_U F_n\\ .$$According to the arbitrariness of $\\delta&gt;0$, we get$$\\inf_K F\\ge \\limsup_{n\\to\\infty} \\inf_U F_n\\ .$$ Fundamental Theorem of $\\Gamma-$ConvergenceTheorem 1 (Fundamental Theorem of $\\Gamma-$Convergence). Let $(X,d)$ be a metric space and $\\{F_n\\}$ be a sequence of functionals. Assume that there exists a compact set $K\\subset X$ such that$$\\inf_K F_n = \\inf_X F_n,\\quad \\forall n.$$If $F$ is the $\\Gamma-$limit of $F_n$, then the minimizer of $F$ exists and$$\\min_X F=\\lim_{n\\to\\infty} \\inf_X F_n.$$Moreover, if $(x_n)$ is a pre-compact sequence such that$$\\lim_{n\\to\\infty} F_n(x_n)=\\lim_{n\\to\\infty} \\inf_X F_n$$then every limit point of $x_n$ is a minimizer of $F$. Proof: Let $\\tilde{x}$ be the point obtained in the proof of proposition 4, then we have$$\\inf_x F \\le \\inf_K F\\le F(\\tilde{x})\\le \\liminf_{n\\to\\infty} \\inf_K F_n=\\liminf_{n\\to\\infty} \\inf_X F_n\\le \\limsup_{n\\to\\infty} \\inf_X F_n\\le \\inf_X F,$$where the last inequality is the limsup inequality. Hence$$F(\\tilde{x})=\\inf_X F=\\lim_{n\\to\\infty} \\inf_X F_n.$$ AcknowledgmentThe above content is summarized based on the video GSS Fall 2016 - Giovanni Gravina: An Introduction to Gamma-convergence on YouTube.","link":"/2026/02/16/Gamma_convergence/"},{"title":"Introduction to Flow Matching","text":"In generative modeling, we are given a collection of training samples $\\{x_i\\}_{i=1}^N$ and wish to generate new samples from the underlying target distribution $\\pi$. There are already many established approaches to this problem, including likelihood-based methods, implicit generative models such as GANs, and score-based diffusion models. More recently, the flow matching framework has emerged as another powerful paradigm. In what follows, we introduce the basic ideas of flow matching and explain how works. BackgroundFor a particle initially at position $x_0 \\in \\mathbb{R}^d$ and a (Lipschitz continuous) velocity field $\\{v_t\\}$, there exists a unique trajectory $\\{x_t\\}$ described by $$\\begin{cases}\\begin{split}\\dfrac{d x_t}{dt} &amp;= v_t(x_t),\\quad t\\in [0,1]\\\\\\x_0&amp;=x_0\\end{split}\\end{cases}.\\tag{Flow-ODE}$$The flow $\\Phi$ collects the trajectories corresponding to different initial positions $x_0$ and is defined by $$\\begin{split}\\Phi: [0,1]\\times \\mathbb{R}^d&amp;\\to \\mathbb{R}^d\\\\\\(t,x_0)&amp;\\mapsto \\Phi(t,x_0)=x_t,\\end{split}$$where $x_t$ denotes the solution of (Flow-ODE) at time $t$. If the flow mapping $\\Phi$ is known, then for any initial position $x_0 \\in \\mathbb{R}^d$ we can obtain the terminal position $x_1$ via $x_1 = \\Phi(1,x_0)$. To determine the flow mapping $\\Phi$, it suffices to know the velocity field $\\{v_t\\}_{t \\in [0,1]}$ and to solve the ordinary differential equation (Flow-ODE). Figure 1: A particle moves from $x_0$ to $x_1$ along the velocity field $v_t$. In general, we aim to use the flow mapping $\\Phi$ to transport the initial distribution $\\mu_0$ to the target distribution $\\pi$. Figure 2: Transport the initial distribution $\\mu_0$ to the target distribution $\\pi$ by the flow mapping $\\Phi$ (or the corresponding vector field $v_t$). Let $\\{X_t\\}$ be a stochastic process with $\\operatorname{Law}(X_t)=\\mu_t$ such that$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ a.e. \\\\\\X_0&amp;\\sim \\mu_0\\end{split}\\end{cases},\\quad t\\in [0,1]$$Then we know $(\\mu_t,v_t)$ must satisfies the following continuity equation$$\\partial_t \\mu_t +\\nabla\\cdot (\\mu_tv_t) = 0,$$which means for all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we have$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t(dy)dt=0.\\tag{CE}$$If $\\mu_t$ has density $\\rho_t$ with respect to Lebesgue measure on $\\mathbb{R}^d$, continuity equation can be written as$$\\partial_t \\rho_t +\\nabla\\cdot (\\rho_tv_t) = 0.$$ Note: The ODE formulation$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ \\text{a.e.} \\\\\\X_0 &amp;\\sim \\mu_0\\end{split}\\end{cases}\\qquad t\\in [0,1]$$is the Lagrangian (particle) viewpoint, while the continuity equation$$\\partial_t \\mu_t + \\nabla\\cdot(\\mu_t v_t) = 0$$is the Eulerian (distribution) viewpoint. One can show that the Lagrangian formulation implies the Eulerian one. Conversely, under suitable assumptions, if the continuity equation holds, then there exists a stochastic process $(X_t)_{t\\in[0,1]}$ solving the ODE above. This result is often referred to as the superposition principle (see [1] for a reference). Hence, once we have learned a “good” flow map $\\Phi$, we can sample $X_0$ from the initial distribution $\\mu_0$ (for instance, a Gaussian $N(0, I_d)$), and then obtain$$\\operatorname{Law}(X_1) =\\operatorname{Law}(\\Phi(1, X_0)) =\\mu_1 \\approx \\pi.$$The central question is therefore: how can we learn such a “good” flow map $\\Phi$, or equivalently, how can we design the vector field $\\{v_t\\}$ using only the training data $\\{x_i\\}_{i=1}^N \\stackrel{\\text{i.i.d.}}{\\sim} \\pi$? Flow MatchingThe main idea of flow matching is to approximate the target vector field $v_t$ by a neural network $u_t^{(\\theta)}$. The neural network is trained by minimizing a suitable discrepancy between $u_t^{(\\theta)}$ and an explicitly known conditional vector field $v_t^x$. To make this precise, we first introduce the conditional probability paths $\\mu_t^x$ and the corresponding conditional vector fields $v_t^x$, and then explain how they relate to the marginal probability path $\\mu_t$ and the marginal vector field $v_t$ that we ultimately wish to learn. Conditional Probability Path and Conditional Vector FieldDefinition 1. The conditional probability path is a path of Markov kernel denoted by $\\mu_t^x$ satisfying: (1) For all $t\\in [0,1]$ and $A\\in \\mathcal{B}(\\mathbb{R}^d)$, the mapping $x\\mapsto \\mu_t^x(A)$ is $\\mathcal{B}(\\mathbb{R}^d)$-measurable; (2) For all $t\\in [0,1]$ and $x\\in \\mathbb{R}^d$, $\\mu_t^x(\\cdot)$ is a probability measure on $\\mathbb{R}^d$; (3) For all $x\\in \\mathbb{R}^d$, $\\mu_0^x\\equiv \\mu_0$ and $\\mu_1^x=\\delta_x$. Note: Property (3) above is used to ensure that the marginal probability path$$\\mu_t(A) := \\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d),$$satisfies $\\mu_0 = \\mu_0$ (our prescribed initial distribution) and$$\\mu_1(A) = \\int_{\\mathbb{R}^d} \\delta_x(A)\\ \\pi(dx) = \\int_A \\pi(dx) = \\pi(A), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d),$$which implies that $\\mu_1 = \\pi$. Hence $\\mu_t$ is a probability path interpolating between the initial distribution $\\mu_0$ and the target distribution $\\pi$, which is exactly what we want. In practice, one may choose a sufficiently small $\\sigma_{\\min} &gt; 0$ and set $\\mu_1^x = N(x, \\sigma_{\\min}^2)$, so that in the end $\\mu_1 \\approx \\pi$. Construction of Conditional Probability PathThere are many ways to construct a conditional probability path $\\mu_t^x$ satisfying the conditions in Definition 1. Here, we adopt a simple conditional Gaussian path$$\\mu_t^x = N(m_t^x,(\\sigma_t^x)^2I_d),$$where$$m_t^x = tx\\quad \\text{and}\\quad (\\sigma_t^x)^2 = (1-t)^2\\sigma_0^2+\\sigma_{\\min}^2,$$with $\\sigma_0^2=1-\\sigma_{\\min}^2$. It is easy to see that$$\\mu_0^x = N(0,I_d)\\quad \\text{and}\\quad \\mu_1^x = N(x,\\sigma_{\\min}^2I_d)\\approx \\delta_x.$$Naturally, we hope our trajectory is$$Y_t^x = m_t^x+\\sigma_t^x Z,$$where $Z\\sim N(0,I_d)$ and we have $\\operatorname{Law}(Y_t^x)=\\mu_t^x$. By differentiating $Y_t^x$ with respect to $t$, we obtain$$\\begin{aligned}\\dfrac{d}{dt}Y_t^x &amp;= \\dot m_t^x+\\dot \\sigma_t^x Z\\\\\\&amp;=\\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (Y_t^x-m_t^x),\\end{aligned}$$where $\\dot m_t^x = \\dfrac{d}{dt} m_t^x$ and $\\dot \\sigma_t^x = \\dfrac{d}{dt} \\sigma_t^x$. Hence, we can choose the conditional vector field$$v_t^x(y):= \\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (y-m_t^x).$$Then we have$$\\begin{cases}\\dfrac{d}{dt}Y_t^x = v_t^x(Y_t^x),\\ \\operatorname{Law}(Y_t^x)=\\mu_t^x\\\\\\Y_0^x\\sim \\mu_0^x\\end{cases},\\quad t\\in [0,1].$$Therefore, $(\\mu_t^x, v_t^x)$ satisfies the continuity equation: for all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we have$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t^x(dy)dt=0.\\tag{CE-conditional}$$ Summary We construct the conditional probability path$$\\mu_t^x = N(m_t^x,(\\sigma_t^x)^2I_d),$$where$$m_t^x = tx\\quad \\text{and}\\quad (\\sigma_t^x)^2 = (1-t)^2\\sigma_0^2+\\sigma_{\\min}^2,$$with $\\sigma_0^2=1-\\sigma_{\\min}^2$ and it satisfies$$\\mu_0^x = N(0,I_d)\\quad \\text{and}\\quad \\mu_1^x = N(x,\\sigma_{\\min}^2I_d)\\approx \\delta_x.$$Then we construct the conditional vector field$$v_t^x(y):= \\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (y-m_t^x).$$And then $(\\mu_t^x, v_t^x)$ satisfies the continuity equation: for all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we have$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t^x(dy)dt=0.\\tag{CE-conditional}$$ Marginal Probability Path and Marginal Vector FieldWe define the marginal probability path $\\mu_t$ by$$\\mu_t(A) := \\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d).$$We have $\\mu_t$ start at our initial distribution $\\mu_0$ and end by$$\\mu_1\\approx \\pi.$$What’s more, we have the following lemma. Lemma 1. For $\\pi-$a.e. $x$, we have $\\mu_t^x\\ll \\mu_t$. Proof : If $\\mu_t(A)=0$, then$$\\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx)=0.$$Since $\\mu_t^x(A)\\ge 0$, we have for $\\pi-$a.e. $x$, $\\mu_t^x(A)=0$. Hence, for $\\pi-$a.e. $x$, we have $\\mu_t^x\\ll \\mu_t$. By Lemma 1, for $\\pi-$a.e. $x$, the Radon-Nikodym derivative$$\\dfrac{d\\mu_t^x}{d\\mu_t}$$exists. Then we can define the marginal vector field as$$v_t(y):= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\pi(dx).$$Note: To some extent, $v_t$ is a weighted average of $v_t^x$. Theorem 2. $(\\mu_t, v_t)$ satisfies the continuity equation. Proof : For all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we need to show that$$I=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t(dy)dt=0.$$In fact, $I=I_1+I_2$, where$$\\begin{aligned}I_1&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\mu_t(dy)dt\\\\\\I_2&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\mu_t(dy)dt.\\end{aligned}$$By using$$\\mu_t(dy) =\\int_{\\mathbb{R}^d} \\mu_t^x(dy)\\ \\pi(dx)$$and$$v_t(y):= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx),$$we have$$\\begin{aligned}I_1&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\ \\mu_t(dy)\\ dt\\\\\\&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;\\xlongequal{\\text{Fubini}}\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\ \\mu_t^x(dy)\\ dt\\ \\pi(dx)\\end{aligned}$$and$$\\begin{aligned}I_2&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\ \\mu_t(dy)\\ dt\\\\\\&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx)\\ \\mu_t(dy)\\ dt\\\\\\&amp;\\xlongequal{\\text{Fubini}}\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\mu_t(dy)\\ dt \\ \\pi(dx)\\\\\\&amp;\\xlongequal{\\text{Chain Rule}}\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\ \\mu_t^x(dy)\\ dt \\ \\pi(dx).\\end{aligned}$$Hence by $(\\mu_t^x, v_t^x)$ satisfies the continuity equation, namely$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t^x(dy)dt=0$$we get$$I=I_1+I_2 =\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\ \\mu_t^x(dy)\\ dt\\ \\pi(dx)=0,$$which means $(\\mu_t, v_t)$ satisfies the continuity equation. By Theorem 2, there exists a stochastic process $X_t$ with $\\operatorname{Law}(X_t)=\\mu_t$ such that$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ a.e. \\\\\\X_0&amp;\\sim \\mu_0\\end{split}\\end{cases},\\quad t\\in [0,1]$$And $\\mu_t$ start at our initial distribution $\\mu_0$ and end by$$\\mu_1\\approx \\pi.$$ Summary We construct the marginal probability path and marginal vector field by$$\\begin{aligned}\\mu_t(A) &amp;:= \\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d).\\\\\\v_t(y)&amp;:= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\pi(dx).\\end{aligned}$$We have $(\\mu_t, v_t)$ satisfies the continuity equation, which means there exists a stochastic process $X_t$ with $\\operatorname{Law}(X_t)=\\mu_t$ such that$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ a.e. \\\\\\X_0&amp;\\sim \\mu_0\\end{split}\\end{cases},\\quad t\\in [0,1].$$And $\\mu_t$ start at our initial distribution $\\mu_0$ and end by$$\\mu_1\\approx \\pi.$$ Now we can answer the question about how to train the neural network $u_t^{(\\theta)}$. TrainingTheorem 3. Define the marginal loss $L(\\theta)$ and conditional loss $J(\\theta)$ by$$\\begin{aligned}L(\\theta)&amp;:= \\int_{0}^{1}\\int_{\\mathbb{R}^d}|v_t(y)-u_t^{(\\theta)}(y)|^2\\ \\mu_t(dy)\\ dt\\\\\\J(\\theta)&amp;:= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|v_t^x(y)-u_t^{(\\theta)}(y)|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\end{aligned}$$We have$$L(\\theta) = J(\\theta)+C,$$where $C$ is a constant independent of $\\theta$. Hence,$$\\arg\\min_{\\theta} L(\\theta)=\\arg\\min_{\\theta} J(\\theta).$$Proof : Expand $L(\\theta),\\ J(\\theta)$ as$$L(\\theta) = A_1-2B_1+C_1,$$where$$A_1 = \\int_{0}^{1}\\int_{\\mathbb{R}^d}|v_t(y)|^2\\ \\mu_t(dy)\\ dt,\\ B_1= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t(dy)\\ dt,\\ C_1= \\int_{0}^{1}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t(dy)\\ dt$$and$$J(\\theta) = A_2-2B_2+C_2,$$where$$A_2= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|v_t^x(y)|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt,\\ B_2=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt,\\ C_2= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt.$$By using$$\\mu_t(dy) =\\int_{\\mathbb{R}^d} \\mu_t^x(dy)\\ \\pi(dx)$$and$$v_t(y):= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx),$$we have$$\\begin{aligned}C_1 &amp;= \\int_{0}^{1}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t(dy)\\ dt\\\\\\&amp;= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;=C_2\\end{aligned}$$and$$\\begin{aligned}B_1&amp;= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t(dy)\\ dt\\\\\\&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx)\\ \\mu_t(dy)\\ dt\\\\\\&amp;\\xlongequal{\\text{Fubini}}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\mu_t(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;\\xlongequal{\\text{Chain Rule}} \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;=B_2.\\end{aligned}$$Since $A_1$ and $A_2$ are independent of $\\theta$, the desired result follows directly. By Theorem 3, we can sample $\\{t_k\\}_{k=1}^K\\sim U[0,1]$; draw from training dataset $\\{x_i\\}_{i=1}^N$; for all $(t_k, x_i)$, draw $M$ samples $\\{y_m^{(t_k,x_i)}\\}_{m=1}^M\\sim \\mu_t^x=N(m_t^x,(\\sigma_t^x)^xI_d)$. And then train our neural network by$$\\min_\\theta\\quad\\dfrac{1}{KNM}\\sum_{k=1}^K\\sum_{i=1}^N\\sum_{m=1}^M |v_{t_k}^{x_i}(y_m^{(t_k,x_i)})-u_{t_k}^{(\\theta)}(y_m^{(t_k,x_i)})|^2.$$ Summary Our goal is to sample from the target distribution $\\pi$. To this end, we first draw samples (for example $x_0$) from an initial distribution $\\mu_0=N(0,I_d)$ and then apply a trained vector field $u_t^{(\\theta)}$, so that at the terminal time we obtain samples (corresponding $x_1$) distributed (approximately) according to $\\pi$ by solving the following ODE$$\\begin{cases}\\begin{split}\\dfrac{d x_t}{dt} &amp;= u_t^{(\\theta)}(x_t),\\quad t\\in [0,1]\\\\\\x_0&amp;=x_0\\end{split}\\end{cases}$$by numerical method such as the Euler method or the Runge-Kutta method. The way to training the vector field $u_t^{(\\theta)}$​ is by$$\\min_\\theta\\quad\\dfrac{1}{KNM}\\sum_{k=1}^K\\sum_{i=1}^N\\sum_{m=1}^M |v_{t_k}^{x_i}(y_m^{(t_k,x_i)})-u_{t_k}^{(\\theta)}(y_m^{(t_k,x_i)})|^2,$$where $t_k\\sim U[0,1], k=1,\\cdots,K$ and $x_i,\\ i=1,\\cdots,N$ draw from training dataset,$$\\{y_m^{(t_k,x_i)}\\}_{m=1}^M\\sim \\mu_t^x=N(m_t^x,(\\sigma_t^x)^xI_d)$$ and$$v_{t}^{x}(y):= \\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (y-m_t^x)$$with $m_t^x = tx\\quad \\text{and}\\quad (\\sigma_t^x)^2 = (1-t)^2\\sigma_0^2+\\sigma_{\\min}^2$ , $\\sigma_0^2=1-\\sigma_{\\min}^2$. There are mainly three types of errors (terminal error) since $\\mu_1^x=N(x,\\sigma_{\\min}^2I_d)\\approx \\delta_x$, there is an error between $\\mu_1$ and target distribution $\\pi$, but we can control this error by choosing $\\sigma_\\min$ sufficiently small. (discretization error) there is an error when solving the ODE above numerically, but we can control this error by choosing step size $h$ sufficiently small. (flow matching error) there is an error between $u_t^{(\\theta)}$ and true vector field $v_t$, but we can assume the neural network can be trained well enough to make this error small enough. In conclusion: Sampling is as easy as learning the vector field! Reference[1] Ambrosio, Luigi, Nicola Gigli, and Giuseppe Savaré. Gradient flows: in metric spaces and in the space of probability measures. Basel: Birkhäuser Basel, 2005. [2] Lipman, Yaron, et al. “Flow matching for generative modeling.” arXiv preprint arXiv:2210.02747 (2022). [3] Kerrigan, Gavin, Giosue Migliorini, and Padhraic Smyth. “Functional flow matching.” arXiv preprint arXiv:2305.17209 (2023).","link":"/2025/11/27/flow_matching/"},{"title":"Introduction to Diffusion Model","text":"Diffusion Model","link":"/2025/10/24/diffusion/"},{"title":"Hello Everyone","text":"Hello everyone! Welcome to my blog! I’ll be sharing my journey as a PhD student at the Academy of Mathematics and Systems Sciences, Chinese Academy of Sciences. This blog isn’t just about my math research – I’ll also explore topics like economics, finance, and anything else that sparks my interest! All the cover images on this blog are taken by myself. If you have any questions or just want to reach out, feel free to email me at wangtuo1020@outlook.com.","link":"/2025/09/10/hello/"},{"title":"Long-Term Trends in Gold and Silver","text":"Dual Drivers of the Gold and Silver MarketCurrency-Driven FactorsThe trends in the gold and silver markets are influenced by two major factors: monetary policy and geopolitical risks. Monetary PolicyThe persistent expectation of interest rate cuts by the Federal Reserve, coupled with the interest rate hikes by the Bank of Japan, have made the global monetary environment more complex. Geopolitical RisksThe current global situation is tense, not only due to increased military conflicts but also due to intertwined risks in energy and shipping. The U.S. blockade on Venezuela, as well as Ukraine’s first attack on Russian shadow fleet ships in the Mediterranean, has heightened risks related to energy prices, transportation costs, market stability, and global supply chains. Furthermore, China has resumed large-scale military drills surrounding Taiwan, further escalating geopolitical tensions. These factors have been significant drivers pushing gold and silver prices higher. Gold Reserves and Military ConflictsWhen a country prepares for military action, it often accumulates large amounts of gold in advance. Gold, as a safe-haven asset, typically sees increased demand during times of international tensions. If gold continues to rise in value, it could indicate that steps toward unification are drawing nearer. Response from Major International BanksWith gold and silver prices continuously reaching new highs, major international banks have been expanding their precious metals trading divisions and logistics capabilities, profiting significantly from these developments. The active participation of banks and financial institutions in the precious metals market has further driven the rise in gold and silver prices. Short-Term Adjustments and Market RisksAlthough the long-term trend in the gold and silver markets remains unchanged, short-term risks still need to be addressed. The recent market adjustments are primarily influenced by the following two factors: Exchange Policy Adjustments: The exchanges have raised margin requirements for gold and silver futures. This action was taken because the rapid rise in gold and silver prices led to an increase in market leverage risks. To prevent concentrated margin calls caused by excessive leverage, which could severely impact the clearing system, exchanges implemented these precautionary measures. Additionally, this is intended to cool down the precious metals market. Market Volatility: The stronger the performance of a commodity, the more deliberate capital market influences are likely to become. Investors in the gold and silver markets may face greater uncertainty in the future. Long-Term Potential of SilverSilver’s Support is Stronger than Gold’sFrom a long-term perspective, silver’s support will likely be stronger than gold’s, which means future volatility could be even more pronounced. In addition to its safe-haven properties, silver has numerous industrial uses, leading to tighter supply. Industrial Applications of SilverSilver plays a crucial role in many industrial fields, especially in photovoltaics, artificial intelligence, and aerospace: Photovoltaics: Silver is essential in solar panels as a key conductive material. Artificial Intelligence: Silver’s excellent conductivity makes it widely used in chip manufacturing. Aerospace: Silver demand is significant in satellite launches and deep space exploration. A medium-sized satellite requires 20 to 50 ounces of silver for its internal components, while larger communication satellites may use as much as 75 ounces or more. Tightening Silver SupplySilver supply mainly comes from by-products of lead-zinc, copper, and gold mining. In 2023, over 70% of global silver production came from these by-products. Over the past five years, the cumulative silver deficit has reached approximately 800 million ounces, nearly equivalent to an entire year’s supply from mining operations. More importantly, the shortage in silver supply is not a new issue, and the World Silver Association predicts that this deficit will persist over the next five years. Silver Inventory StatusDespite the ongoing rise in gold and silver prices, the physical inventory at exchanges has not significantly increased. For example, the Shanghai Gold Exchange has maintained low silver inventories. In November 2025, silver stocks hit their lowest level since January 2016, indicating that silver is being hoarded, and this phenomenon is clearly not being driven by retail investors. ConclusionIn this resource-driven era, gold and silver are vital investment assets and should be held with a long-term perspective. The cover image in this article was taken at Lake Königsee, Germany.","link":"/2026/01/03/gold_silver_invest_jan_2026/"},{"title":"Optimization over the Space of Probability Measures","text":"This is the talk I presented in the Optimization Group Seminar, titled: An Introduction to Optimization over the Space of Probability Measures: From Sampling to Wasserstein Gradient Flow. Click here to download the slides. The cover image of this article was taken on the way to Glenorchy, New Zealand.","link":"/2026/01/27/optimization_over_probability_measures/"}],"tags":[{"name":"Sampling","slug":"Sampling","link":"/tags/Sampling/"},{"name":"Stochastic Process","slug":"Stochastic-Process","link":"/tags/Stochastic-Process/"},{"name":"Optimization","slug":"Optimization","link":"/tags/Optimization/"},{"name":"Calculus of Variations","slug":"Calculus-of-Variations","link":"/tags/Calculus-of-Variations/"},{"name":"Generative Modeling","slug":"Generative-Modeling","link":"/tags/Generative-Modeling/"},{"name":"Diffusion Model","slug":"Diffusion-Model","link":"/tags/Diffusion-Model/"},{"name":"Investment","slug":"Investment","link":"/tags/Investment/"},{"name":"Optimization over the Space of Probability Measures","slug":"Optimization-over-the-Space-of-Probability-Measures","link":"/tags/Optimization-over-the-Space-of-Probability-Measures/"}],"categories":[{"name":"Sampling","slug":"Sampling","link":"/categories/Sampling/"},{"name":"Calculus of Variations","slug":"Calculus-of-Variations","link":"/categories/Calculus-of-Variations/"},{"name":"Investment","slug":"Investment","link":"/categories/Investment/"},{"name":"Optimization over the Space of Probability Measures","slug":"Optimization-over-the-Space-of-Probability-Measures","link":"/categories/Optimization-over-the-Space-of-Probability-Measures/"}],"pages":[{"title":"Between Sampling and Optimization","text":"Introduction​ Let $p$ be a positive integer and $f:\\mathbb{R}^p\\to \\mathbb{R}$ be a measurable function such that$$\\int_{\\mathbb{R}^p} e^{-f(x)} dx&lt;+\\infty.$$In various applications, one is faced with the problem of finding the minimum point of $f$ or computing the average with respect to the probability density$$\\pi(x) = \\dfrac{e^{-f(x)}}{\\int_{\\mathbb{R}^p} e^{-f(u)}du}.$$ In other words, one often looks for approximating the values $ x^{*} $ and $ \\bar x $ defined as $$x^{*} \\in \\arg\\min_{x\\in \\mathbb{R}^p} f(x), \\quad \\bar x = \\int_{\\mathbb{R}^p} x \\pi(x) dx.$$ AssumptionAssumption 1. We assume $f$ is strongly convex with Lipschitz continuous gradient. That is, we assume that there exist two positive constants $m$ and $M$ such that for all $x,y\\in \\mathbb{R}^p$,$$f(y)-f(x)-\\nabla f(x)^T (y-x)\\ge \\frac{m}{2}||y-x||_2^2,$$and$$||\\nabla f(x)-\\nabla f(y)||_2\\le M ||x-y||_2.$$ Langevin Monte Carlo (LMC) Algorithm​ Starting from an initial point $x^{(0)}\\in \\mathbb{R}^p$ that maybe deterministic or random, the iterations of the algorithm are defined by the update rule$$x^{(k+1,h)} = x^{(k,h)}-h\\nabla f(x^{(k,h)})+\\sqrt{2h}\\ \\xi^{(k+1)};\\quad k=0,1,2,\\cdots \\tag{LMC}$$where $h&gt;0$ is the tuning parameter, refer to as the step size, and $\\xi^{(1)},\\cdots,\\xi^{(k)},\\cdots$ is a sequence of mutually independent, and independent of $x^{(0)}$, centered Gaussian vectors with covariance matrices equal to identity. Let $\\nu_k$ be the distribution of the $k$-th iterate of the LMC algorithm, that is $x^{(k,h)}\\sim\\nu_k$. Main Idea of LMC Algorithm​ The Markov chain $\\{x^{(k,h)}\\}_{k\\in \\mathbb{N}}$ is the Euler-Maruyama discretization of the following Langevin dynamic SDE:$$dL_t = -\\nabla f(L_t)+\\sqrt{2}dW_t,\\quad t\\ge 0,$$where $\\{W_t;\\ t\\ge 0\\}$ is a $p-$dimensional Brownian motion, $\\{L_t; t\\ge 0\\}$ is known as Langevin diffusion. When $f$ satisfies Assumption 1, the above SDE has a unique strong solution which is a Markov process. ​ By Fokker-Planck Equation, we know $\\{L_t; t\\ge 0\\}$ has $\\pi$ as invariant density, namely if $L_0\\sim \\pi$ then $L_t\\sim \\pi$ for all $t\\ge 0$. ​ Under Assumption 1, when $h$ is small and $k$ is large (so that the product $kh$ is large), the distribution of $x^{(k,h)}$ is close in various metrics to the distribution $\\pi$ with density $\\pi(x)$. So the question is how to quantify this closeness? Wasserstein DistanceDefinition 1. For two measures $\\mu$ and $\\nu$ defined on $(\\mathbb{R}^p,\\mathcal{B}(\\mathbb{R}^p))$, the $2-$Wasserstein distance is defined by$$W_2(\\mu,\\nu) = \\left( \\inf_{\\gamma\\in \\Gamma(\\mu,\\nu)}\\int_{\\mathbb{R}^p\\times \\mathbb{R}^p}||x-y||_2^2d\\gamma(x,y)\\right)^{1/2},$$where the infimum is with respect to all joint distributions $\\gamma$ having $\\mu$ and $\\nu$ as marginal distributions. Here we review some important properties of Wasserstein distance. Proposition 1. For two Dirac measure $\\delta_x$ and $\\delta_y$, we have $$W_2(\\delta_x,\\delta_y) = ||x-y||_2.$$Proposition 2. The infimum in the definition of Wasserstein distance is achievable. That is to say there exists a joint distribution $\\gamma^*\\in \\Gamma(\\mu,\\nu)$ such that $$W_2(\\mu,\\nu) = \\left( \\int_{\\mathbb{R}^p\\times \\mathbb{R}^p}||x-y||_2^2d\\gamma^*(x,y)\\right)^{1/2}.$$ Main Theorem Theorem 1. Assume that $h\\in (0,\\frac{2}{M})$. The following claims hold: (a) If $h\\le \\frac{2}{m+M}$ then $W_2(\\nu_k,\\pi)\\le (1-mh)^k W_2(\\nu_0, \\pi)+ \\frac{M}{m}(5hp/3)^{1/2}.$ (b) If $h\\ge \\frac{2}{m+M}$ then $W_2(\\nu_k,\\pi)\\le (Mh-1)^k W_2(\\nu_0, \\pi)+ \\frac{Mh}{2-Mh}(5hp/3)^{1/2}.$ Relation with OptimizationThe function $f(x)$ and the function $f_\\tau(x):=f(x)/\\tau$ have the same minimizer $x^{*}$, whatever the real number $\\tau&gt;0$. If we define the density function $\\pi_\\tau(x)\\propto \\exp(-f_\\tau(x))$, then the average value$$\\bar x_\\tau = \\int_{\\mathbb{R}^p} x \\pi_\\tau (x)dx$$tends to the minimizer $x^* $ when $\\tau\\to 0$. Furthermore, the distribution $\\pi_{\\tau}$ tends to the Dirac measure $\\delta_{x^{*}}$.","link":"/LMC_GD.html"},{"title":"What is Economy?","text":"Three Main Problems for Economy How People Make Decisions How People Interact How the Economy as a Whole Works Ten Principles of EconomyHow People Make Decisions People face tradeoffs. The cost of something is what you give up to get it. Rational people think at the margin. People respond to incentives. How People Interact Trade can make everyone better off. Markets are usually a good way to organize economic activity. Governments can sometimes improve market outcomes. How the Economy as a Whole Works The standard of living depends on a country’s production. Prices rise when the government prints too much money. Society faces a short-run tradeoff between inflation and unempolyment. 1. People face tradeoffsThere is no such thing as a free lunch! To get one thing, we usually have to give up another thing. 2. The cost of something is what you give up to get itThe opportunity cost of an item is what you give up to obtain that item. 3. Rational people think at the marginMarginal changes are small, incremental adjustments to an existing plan of action. 4. People respond to incentivesMarginal changes in costs or benefits motivate people to respond. The decision to choose one alternative over another occurs when that alternative’s marginal benefits exceed its marginal costs! 5. Trade can make everyone better offPeople gain from their ability to trade with one another. Competition results in gains from trading. Trade allows people to specialize in what they do best.","link":"/economy_what_is_economy.html"},{"title":"About Me","text":"Hello","link":"/about.html"},{"title":"《全球视野下的投资机会》（第一章读书笔记）","text":"今天是感恩节，因此我想先用本书的作者，时寒冰先生说过的一句话开头： 感恩已经得到的，不要为没有得到的焦虑 第一章 高盈利的源头抓住财富的密码：顺势而为，正确的时间将钱放在正确的市场小钱是辛苦挣来的，大钱则是靠超前的眼光投资赚得的。然而有的人投资获得了巨大的成功，而有的人却穷其一生，除了累累伤痕，心力交瘁，一无所获，原因可以归纳为一个字：“势”。 所谓“势”，就是资本、资源、人口等流动的方向。 中国经济的真正腾飞始于2001年：中国加入世界贸易组织（WTO），全世界资本开始流入中国。 中国本应借助这种经济高速增长的势头，大力发展高端制造业，全面提升中国的科技水平和制造业水平，但房地产的过度投机犹如黑洞，将不计其数的宝贵资源吸入其中，在一定程度上制约了中国的产业技术升级。这也改变了大趋势。 2018年中美贸易战开始，逆全球化浪潮逐渐兴起，逐渐与欧美等发达国家脱钩断链。高端产业回流欧美日等发达国家和地区，低端产业向东南亚、墨西哥等发达国家转移。 2020年的新冠疫情强化了这一趋势。印度、日本等国股市持续大幅度上涨，但日本的制造业体系更为完善，供应链也极为完整，而且在技术、劳动力等方面有明显的优势，因而日本的重要性凸显，相应的日本的股市和楼市得到了强有力的支撑。 资本流入之地，无论是股市还是楼市，都容易上涨。而资本流出之地，无论是股市还是楼市，都容易下跌。 从行业角度看，资本流动的方向同样是具有决定性的主导力量。 人工智能刚进入初始阶段，未来还有很长一段路要走。2022年底后，AI飞速发展，使得人类从石油驱动经济发展时代逐步步入电力驱动经济发展时代。在过去石油有多重要，未来电力就有多重要。 机器人的发展尤其值得重视。制造机器人的材料需要靓号得机械性能，物理性能和化学性能，因此那些质量轻、强度硬度高、耐磨损、耐腐蚀的材料需求极大，例如PEEK、镁合金、钛合金、铝合金、碳纤维、汝铁硼磁材等。 只有在正确的时间将钱放在正确的市场中才能赚钱并且赚大钱。 正确的市场，就是只要选对品种或者选对企业，哪怕有剧烈的调整，也能很快修复，并持续给你带来可观的投资回报的市场。 错误的市场，就是这个市场已经经过漫长的时间检验，它除了吞噬你的财富或者本钱以外，不能给你带来任何像样的回报。 不要用侥幸和幻想美化现实的残酷，要想获取财富，必须战胜幻想。 紧抓稀缺性物以稀为贵，以稀缺性为目标，是获取高盈利的捷径，但必须考虑时间因素，时间是成就、强化稀缺性的帮手，同时也是摧毁、击败稀缺性的利器。 投资上的稀缺性是指：在某个时间段内（时间长短可由稀缺性的强度而定），某种商品的需求稳定或增长，而供应无法同步增长甚至还可能减少的特性，并且，这种商品在某个阶段内缺乏充分的替代商品，从而导致该商品的供给在该时间段内无法满足需求（消费需求与投资需求）。 供给有限 缺少替代商品或者替代商品不足 需求稳定或增长 强调某个时间段内 稀缺性的分类： 地域稀缺性：某种商品只有这个地方有，而别的地方没有，那么这种稀缺性从空间角度看就是无可替代的。例如茅台。 技术稀缺性：带有新明的垄断特色。例如：英伟达、微软、谷歌等公司，反例如英特尔。技术不仅制造稀缺性也摧毁稀缺性，例如钻石。 不可再生稀缺性：指这种资源原本就很少，而且随着人们的开采、使用会越来越少。但是某段时间内，供应的增长会摧毁稀缺性。例如铟、稀土、可可等。 库存增加，意味着稀缺性的基础在消费降级阶段非常容易坍塌，要顺势而为，及时调整。 稀缺性不仅仅适用于投资，也同样适用于做实业和做人。在人心冷漠的时候，用良心做事所具有的稀缺性，就是最大的号召力，会带来好的回报。 与确定性趋势同行对普通人来说，判断趋势只需要关注 消费、就业和人口。 消费是最直接反应经济现状和未来前景的指标：当一个国家的人满世界抢购奢侈品的时候，这个国家处于明确的上升周期，经济增长势头强劲，房价也会因为获得强大的支持而猛烈上涨。当消费不断降级，人们对商品价格斤斤计较，甚至生活必需品的消费都开始缩减的时候，这说明整个经济处于收缩阶段，此时房价，股市，汇率等承受巨大压力，投资容易亏损。 人口也是判断投资趋势时非常重要的一个因素：一切经济活动归根结底围绕着人进行，生产的东西要卖给人消费，建造的房子要卖给人住。人口如果是增长的，经济上行的动力就更足，反之亦然。历年全国小学数量与招生人数是研究人口变化的一个非常重要的前瞻性指标。由于人口惯性，总人口的萎缩会滞后于出生人口的萎缩，因而不能及时反映人口衰减的严峻性以及其对经济社会的深刻影响。如果只按目前这种力度鼓励生育，中国毫无疑问将在几十年内成为老龄化程度和人口萎缩最严重的国家之一。人口的趋势一旦转变，就很难逆转。人口的变化是房价的一个根本性影响因素。 人口的下降，让房地产的供应显而易见地过剩，而这种趋势会日益明显。因此，依赖房地产拉动经济增长的路子走不通了，必须改变；需要采用以科技创新促进经济增长，以民富路线刺激消费、拉动经济增长的高质量发展模式。 很多人做投资容易犯一个错误，那就是他们总是根据现实的情况做决策。其实，投资交易的是未来，确切地说，应该基于对未来的判断在当下做交易。房地产投资尤其如此。年轻人按揭买房，抵押的并不是现在，而是自己未来几十年可能实现的收入。这是基于未来希望而在当下交易的行为。房地产产业链的各个环节，都是围绕着最核心的群体–年轻群体进行的。只要经济发展只要就业机会好，希望就在。希望在，房地产行业的暴利就能维持。反之，这种交易就会停止。所以，判断房价的走势非常简单，看看年轻群体对未来的希望和激情，看他们处在什么样的状态之下，就一目了然了，从长期趋势来看，人口是增长还是下降(决定需求)，经济是增长还是衰退(决定购买力)，房地产供应是增长还是下降(决定供给)，是决定房价涨跌的关键，也是我们判断未来房价走势的关键。其中，人口因素尤其重要。 固有观念是投资者的敌人，也是投资者最大的心魔之一。例如即便是古人基于自身经验所说的“一铺养三代”的商铺，在电子商务深人每个角落的情况下，其价值也在发生着巨变。电子商务的高速发展蚕食了商铺的价值，让商铺的投资价值变得越来越弱。 想获取高额利润，规避风险，我们做投资决策时必须足够迅速和果断。天下武功无坚不摧，唯快不破。当你发现一个别人没有意识到的好的商机时，应该迅速行动。等别人意识到，想追上来，而你因缺乏独家技术从而无法享有垄断优势的时候，你就要果断将机会转让出去。 因为，在中国投资的特点就是，人多、机会少、资源少、市场不足，尤其是与发达国家的市场“脱钩”之后，国内市场的争夺变得更加激烈。无论哪个领域，只要刚开始赚钱，人们就会一窝蜂地冲上去，用不了多久就会供应过剩，投资者只有赶在供应过剩之前出手才能卖出好价钱，才能体面而安稳地退出。适时退出，也是优秀投资的一个组成部分。 有的时候，某些领域看似风险很大，却需要投资者坚定地往前走。比如，发达国家市场与中国的“脱钩”，对很多行业来说是显而易见的利空影响，但对芯片行业来说却是为数不多的例外之一。当美国对中国的芯片产业一而再、再而三地进行制裁、打压的时候会产生一种反作用力，倒逼中国国产芯片产业发展。虽然在研制高端芯片方面还有很长的路要走，但对于中高端芯片，几乎可以说，这一领域以后就是中国的天下了。这是头部国产芯片的历史性发展机遇。“脱钩”使中国芯片产业高速发展。 全球市场是连通着的。基于同样的规律，中国严厉管控和限制战市场中的相关企业则是重大利多略稀缺矿产资源的出口，对美国资本支持。比如，中国严厉管控锑的出，美国锑业公司 (United States Antimony Corporation，美股代码: UAMY)、珀佩图阿资源公司(Perpetua Resources，又名加拿大金锑矿业公司，美股代码: PPTA) 的股价就获得了强大的支撑力量，因此持续上涨。中国管控稀土的出口，美国稀土类企业的股价就会大幅上涨。比如，致力于建立一个垂直整合的美国国内稀土元素磁体生产供应链的公司–美国稀土有限责任公司(USA Rare Earth，美股代码: USAR)，以及美国最大的稀土矿公司，同时也是美国唯一一家全产业链一体化的稀土生产商–MP材料公司(MP Materials，美股代码: MP)，它们的股票就非常容易受到资金的青睐。 投资者如果停留在过去，就看不到趋势的演变。仅根据过去的经验做投资是危险的。人可以重视经验，但必须往前看，不能被过去的经验束缚住。 很多投资品种的趋势是变化着的。在美国，拜登政府时期，大力鼓励发展新能源，新能源板块走势强劲;而在“特朗普 2.0”时期，美国政府的政策是大力鼓励发展传统能源对新能源的发展则充满了抵触和排斥倾向。但是，这种极端政策的骤然转换，实际上也带来了一些好的、长远的投资机会。比如，充电桩类公司的股票。美国有两家具有代表性的充电服务公司，Blink Charging Co.(美股代码: BLNK) 和ChargePoint Holdings Inc.(美股代码: CHPT)。在拜登政府时期，Blink Charging Co.的股价曾经涨到 64.5 美元的历史高位;而在“特朗普2.0”时期，它的股价跌到了1美元以下的位置。同样地，ChargePoint Holdings Inc.的股价，在拜登政府时期达到过49.48美元的历史高点;而在“特朗普2.0”时期，也跌到了1美元以下的位置。特朗普政府的打压，让人们忘记了新能源汽车依然是未来的大势所趋。看一下现在满大街的加油站，我们就能知道，未来，取代这些加油站的，将是一个个的充电站。因此，特朗普政府对新能源的嫌弃和打压实际上为投资者做长远投资带来了一次好机会。未来，当美国一位青睐新能源的总统走马上任时，这些跌人谷底的充电服务类公司恐怕又会生机勃勃，只不过我们恐怕再也看不到如此低的股价了。当然，前提是这些公司能活着度过“冬天”最暗淡和痛苦的阶段。 我们有限的资金，要永远投在有生命力、有价值的领域和品种上。随着时间的流逝，这些品种的价值更加凸显。也许，过去人们曾经忽略它们，但在接下来的这个经济大周期，它们必将大放异彩。 市场的不确定性越高，蕴含的风险越大。人们往往只看到可能的收益而忽略风险，这样的结果往往很悲惨。 追求确定性盈利，在确定性高的时间节点人手最具确定性的品种这是获取高收益的非常重要的保障。 好眼光需要建立在空间思维的基础之上。所谓空间思维也称“多元思维”、“全方位思维”、“整体思维”或“多维型思维”，是指跳出点、线,面的限制，从上下左右、四面八方去思考问题的思维方式。很多人拥有非黑即白的简单思维习惯，缺乏空间思维能力。越是在自媒体的碎片化信息中流连忘返的人，越缺乏空间思维能力，目光越短浅，而且这种短浅往往是难以改变的。 一个心怀感恩的人，要比一个心中充满仇恨和暴戾之气的人，具有更敏锐的眼光和更聪明的大脑。作为一个趋势分析者，你要想有独到的眼光，看得更远、更透彻，就必须摆脱非黑即白的思维方式，培养自己的空间思维能力。作为一个投资者，你只有摆脱固有的种种局限，让思维彻底解放开来，才能获得洞悉世界、发现好机会所带来的巨大快感。 基本的逻辑思维能力可以帮助我们剔除无用的东西，留下最有价值的，让趋势的推导有依据、有章法，而且，逻辑本身就带有纠错的功能让我们更容易确定趋势的方向。分析趋势，寻找好的投资机会，是一项系统的工程。很多时候，我们需要最大限度地去除感情因素，站在利益相关方的角度去思考、去理，找出各个利益相关方最有可能做出的选择。比较这些选择对趋势可能产生的综合影响，我们才能精准判断趋势的方向。","link":"/global_investment.html"},{"title":"Analogy between Sampling and Optimization","text":"Analogy between Sampling and Optimization","link":"/sampling_optimization.html"},{"title":"Long-Term Trends in Gold and Silver","text":"金银大趋势金银：货币端+地缘政治双重推动 货币端：美联储持续降息预期+日央行加息 地缘政治：不仅局势紧张，已经和能源与航运风险牵扯到了一起：美国封锁委内瑞拉的邮轮和乌克兰首次在地中海袭击俄罗斯影子舰队邮轮，等于现在能源价格，运输价格，市场稳定性和全球供应链都面临着深远的影响，再加上中国时隔9个月再次启动了全面包围台湾地区的军事演习紧张气氛越来越浓，这些都是金银飙升的重要推动力。 当一个国家准备开展军事行动的时候，会提前大量囤积黄金，而当一个国家持续大量囤积黄金的时候，也可能是为了应对未来的突发冲突。如果黄金一直强势上涨，也意味着统一的脚步越来越近了。 在金银价格屡创新高的背景下，国际大行几乎都在扩大贵金属交易部门规模及物流能力，从中获利颇丰他们也愿意看到贵金属的行情。 虽然大趋势没有扭转，但是短期风险需要释放。这波调整原因有二：交易所进行重大政策调整，全面上调金银等金属期货的履约保证金，这是因为金银涨势过快，杠杆越积越高，再不干预一下，万一出问题集中爆仓，清算体系将面临巨大冲击，这是交易所的自保行为，也有意给贵金属市场降温。 越是势头猛的品种，未来资本刻意影响市场的情况也会越严重。 从更长远角度看，银的支撑会比金更强，也意味着未来波动会更强烈。银在具备黄金避险属性的的同时，多数的工业属性导致供应更加紧俏。除了众所周知的光伏以外，AI也离不开白银，毕竟白银才是导电率最高的金属芯片卷，性能卷速度那就需要超强的导电性。航空航天同样需要大量的白银，从卫星发射到深空探测已经都起着至关重要的作用。相关数据显示，一颗中型卫星的内部组件需要用20至50盎司的银大型通信卫星，可以使用75盎司甚至更多。更重要的是，这些银上了太空，多数可就回不来了，算总数现在至少13万盎司的银上太空，并且无法回收再利用了。更何况，白银还不是想挖就能挖出来的，绝大多数白银都来自于铅锌，铜，金矿的副产品。比如2023年矿产，银产量的比重是70%以上。种种原因堆积到一起，白银短缺早就不是什么新鲜事了。过去五年，白银累计赤字已经达到八亿盎次左右，几乎相当于正常情况下矿山一整年的供应量。而且世界白银协会还预测，这种赤字状况并不会缓解，未来五年内将持续存在。在这样的背景下，交易所的实物库存始终上不来。我国这边上海黄金交易所白银库存也保持低位。2025年11月更是创下了2016年一月以来的库存新低，这表明有人很明显在囤积白银，而且散户不可能做得到。","link":"/gold_silver_invest_jan_2026.html"},{"title":"2025资产配置报告","text":"重要声明：本文仅为本人2025年度资产配置感想，不构成任何投资建议。且本人才疏学浅，刚正式着手资产配置不到一年，故无法保证任何观点的绝对正确性。 Download PDF 时间过的真快，转眼一年就快过去了。2025年是十分不平凡的一年，就在这短短的一年里，美股、黄金、白银、BTC均创造历史新高。今年也是我首年切身参与资产配置，读了一些书籍，参与了上百次交易，吃到了一些“肉”，因而在年底结算之日，做如下感想。 不论是过去，现在，还是将来，资产配置都非常重要。众所周知，钱不等于财富，而事实上财富应该是购买力的体现，而资产配置就是想方设法去保有或增长我们的购买力，因此其重要性也是不言而喻的。在我看来，一个合格的资产配置应该做到： 在选择正确的货币和正确的市场的基础上，顺势而为、全球配置、风险对冲、价值投资、定期调整。 选择正确的货币什么是正确的货币？对货币而言，最重要的是货币的信誉，而所谓货币的信誉就是我持有那张纸币，几年，甚至几十年其购买力不变。 那么CNY是正确的货币吗？显然不是。或许比我年长的人都有过这样的经历：曾经还在使用“分”这样的硬币，但是从我记事起就没有用过；曾经有一万CNY就是比较有钱的状态，甚至称为“万元户”，而现在一万CNY简直不值一提；随着年龄的增长，我们能够明显的感觉到物价的逐渐上涨，尤其是疫情之后。 几十年前的10 CNY也是能够买很多东西的，而现在呢？今年我在美国Saipan旅游时，绝大多数地方低于10 USD不能刷信用卡，必须付现金，而我挑选了很长时间东西，也没能凑够10 USD，最终被迫付的现金。同样的几十年时间，USD的购买力并没有发生太大的改变，而CNY确发生了大幅度贬值。 或许有的人认为这是过去的事情，是由于那几年中国飞速发展导致的不可避免的通货膨胀，而如今中国已然处于通货紧缩的状态。但是事实真是如此吗？ 回答这个问题之前，我们首先需要弄清楚货币从何而来？有点常识的人应该都知道，当前货币早已成为信贷货币，即大部分“钱”是由贷款所“创造”，这也是为什么过去中国房价会大幅度增长的原因之一：过去中国“创造”的货币主要来自于房贷，这是中国货币的出水口。而2020年12月31日，央行和银保监会联手颁布了一条关于房贷的重磅政策《关于建立银行业金融机构房地产贷款集中度管理制度的通知》，并于2021年1月1日起立即实行，对银行房地产贷款和个人住房贷款给出了极其明确的比例限制，也就是说“货币的水龙头”被关上了，而且随着2018年中美贸易脱钩，产业开始大转移：高端制造业回流欧美日等发达国家，低端制造业向东南亚、墨西哥等地方转移。这也是为什么2021年中国房价开始大幅度下跌，以及为什么全款买房是愚蠢至极的行为：买房子要么不买，要么就用贷款买。同样的道理，我们可以通过信用卡和花呗等方式赚一些小钱：将几乎全部的钱用于资产配置，并将月预计消费额买入货币基金等安全的理财方式，月内使用信用卡/花呗等方式消费，还款日用下个月工资进行还款，这样我们能收获月消费总额的一点点利润，除此以外，找同学吃饭后A钱并将收到的钱再次放入资产配置，可以实现某种“杠杆”效应。但是根据本人实践表明，这样做也是有风险的：一个是信用卡/花呗等方式无法完成转账的操作，因此还需在活期留有少量资金；另一个是工资的发放可能是不稳定的，如若还款日之前没有收到预期工资可能会引发个人还款危机，因此最好还是在还款日之前通过赎回等方式以保证还款日附近资金流动性充裕。 为此，我们当前货币情况不应该去只关注现金的量，而应该关注M2广义货币总量。根据中国人民银行和美联储公布的数据，截至2025年11月，中国M2广义货币总量为336.99万亿元CNY，按照11月月末USD/CNY汇率计算，约为47.63万亿USD；而美国M2广义货币总量为22.322（季调）/22.330（非季调）万亿USD，取其大为22.33万亿美元。考虑到中美M2广义货币的计算方式不同，我们将美国的数据加上美国所有商业银行大额定期存款2.415 万亿USD，加以比较，我们发现：截至2025年11月，中国M2广义货币总量是美国M2广义货币总量与美国所有商业银行大额定期存款之和的1.92倍！ 事实上当钱中国M2广义货币总量为全球第一，且遥遥领先，且其货币的发行不像美国那样受到多方约束。除此以外，美国的货币是全球性货币，在全世界流通，超发的货币被全世界消化；而中国的货币主要在中国大陆流通，几乎由中国大陆内部消化，因此货币超发的后果是不言而喻的。 我们还可以通过另一个角度来印证这件事：一国货币的超发到底谁最清楚？当然是央行自己！而我们的央行又在做一些什么呢？答案是购买黄金、白银等贵金属。 至于中国“超发”了如此巨量的货币，这几年中国为什么会表现出通货紧缩的状态呢？事实上物价的涨跌并非由货币的超发与否直接决定。自2018年贸易脱钩以来，中国大量的出口贸易受到严重影响，因此大量的产品不得不从出口转为内销，进而参与国内内卷，使得国内大量产品出现了严重的产能过剩，即供给增加，但是随着中国经济的整体下行，人们消费欲望也随之降级，因而总体需求下降。故因为严重的供过于求，短时间内对冲掉了货币超发带来的问题，进而使得物价整体下跌。但是，这显然是暂时的，当未来因内卷导致企业优胜劣汰，产能下降的时候，货币超发所带来的货币贬值问题无疑是巨大的。除此以外值得一提的是，根据中国发布的消费者价格指数(CPI)，仅仅30年内CNY的贬值不应该像现实情况这样严重，因此这一数据的统计也是十分值得怀疑的。 除了要考虑通货膨胀问题，货币的汇率稳定也是极其重要的。如果选择了一个汇率不稳定的货币，那么再高的收益率也会灰飞烟灭。一个经典的例子就是俄罗斯卢布(RUB)，1989年11月1日之前，按照当时苏联的汇率，大约 0.63 RUB兑换 1 USD，1989年11月1日后，苏联国家银行将汇率调整为 6.27 RUB兑换 1 USD，贬值为原来的$1/10$左右，而且卢布的贬值仍在继续，到1992年9月下旬，1299RUB兑换1USD，随后1998年1月1日，俄罗斯发行新卢布，兑换率为1000旧卢布兑换1新卢布，到最近2025年12月大约 77.69 RUB兑换 1 USD，对应旧卢布 77,690 旧卢布兑换 1 USD，因此RUB总体贬值约为原来的$1/123317$，也就是说曾经在1989年11月之前有1千万RUB现金的千万富翁，如果没有采取任何应对措施，现在也只剩下 81.09 RUB，大概也就买得起一条面包。 除此以外，货币是一个国家综合经济实力的体现，还需要考虑很多其他的因素。例如日元作为全球最大套利货币，长期以来已然对日元的汇率乃至日本的经济状况造成了一定影响，这也是为什么日本今年宣布加息，但是加息不及预期，侧面反映了日本当前经济问题依旧严峻，因此日元长期来看或许也不是正确的货币。此外，随者俄乌冲突的持续，欧债危机也即将爆发（这也是美国总统特朗普真正想要的），未来欧元区是否会解体，依旧是个未知数。而美元作为当前世界上做大的清算货币、储备货币、计价货币，依靠美国的科技与军事霸权，通过美元的潮汐，美元的环流影响这个世界。因此哪怕是现在美元处于弱势周期，美元依旧具有强有力的支撑，因此在这个CNY相对USD升值的周期里，尽可能兑换美元才是明智之举。 选择正确的市场除了选择正确的货币，选择正确的市场也是十分重要的。著名股神巴菲特(Warren Buffett)曾在演讲中提及”I have been born in the right place”, “…most important of all – the American Tailwind.” 他把他的成功很大原因归结于他生在了正确的地方，选择了正确的市场。 那么什么是正确的市场？正确的市场，就是只要选对品种或者选对企业，哪怕有剧烈的调整，也能很快修复，并持续给你带来可观的投资回报的市场。一个正确的市场，往往是一个法制健全的市场，其财务造假成本极高。一个正确的市场，往往也是更符合生物进化法则的：一个优胜劣汰，适者生存的市场，在这样的市场中，只要选择脱颖而出的企业，那就能够获得丰厚的利润。 那么什么是错误的市场？错误的市场，就是这个市场已经经过漫长的时间检验，它除了吞噬你的财富或者本钱以外，不能给你带来任何像样的回报。除此以外，如果一个市场法制不健全，财务造假成本极低，甚至财务造假成为各个公司之共识，不以为耻，反以为荣，以至于良心都具有稀缺性的市场，这样的市场又怎会是正确的市场？此外，如果一个市场的大部分参与者的文化习惯都急功近利，总是渴望赚快钱，投资以尽快赚钱为唯一标准，这样的市场又怎么会好？ 只有在正确的时间将钱放在正确的市场中才是正确的资产配置。 风险对冲、全球配置、价值投资、定期调整所谓风险对冲，就是指配置的资产不应同时涨跌，也俗称：鸡蛋不能放在一个篮子里。一个合格的资产配置者，首先应当考虑的是风险而非收益。对任何一个国家而言，都必然有其自己的经济周期，因此资产的全球配置十分重要，而且要根据局势进行定期调整，这样能够对冲掉一部分风险。此外，资产配置不等于投资，很重要的一点是适配：根据自己的风险承受能力，将资产分散配置于保险（尤其是保险业全球第一的香港保险）、定期存款（大额存单），货币基金，房地产，美债、美股、黄金、白银等贵金属…一个合格的资产配置首先要保证自己这样做之后不会整天提心吊胆，睡不安稳，也只有这样才能够按计划长期持有，不被一些突如其来的变故搞得乱了阵脚。 一个合格的资产配置者，必须学会价值投资，而非只看价格。去买入任何一个东西之前，都应该谋定而后动，必须能够讲清楚这是个什么东西，它为这个社会创造了怎样的价值，买它为什么能够让我盈利？再此基础上，再去考虑其价格现在是不是过高，以怎样的价格买入能够最小化风险？如果一个行业，一个公司的存在只是为了赚钱，甚至是以牺牲别人的财富为代价，那么这个行业或者公司哪怕现在高盈利，也一定走不长远。事实上这也是投资和赌博的最大区别：你是否对你买入的东西有充足的认知。合格的资产配置绝不应该是本末倒置的先看价格，只看钱的数量。相信一个有点认知的人都明白这个道理：财富永远伴随着价值而来。 一个合格的资产配置者，必须懂得和时间做朋友，不能急功近利。一个急功近利想赚块钱的人，哪怕取得过阶段性的成功，也终将获得失败。事实上做任何事情也是如此，一个为了考试目的而学习的人终究学不好一门课，一个只是为了发论文的科研也毫无意义。一个人如果在一生中干任何事情都是急功近利，那么这一生也活得毫无意义，而且这多半是其从小的教育导致的，是难以改变的，身处一个这样的人很多的社会，只能尽可能的少与这样的人交往，而事实上这也是我从小到大与人交往的基本原则与底线。 顺势而为众所周知，小钱是辛苦挣来的，大钱则是靠超前的眼光投资赚得的。而投资最重要的就是顺势而为，而分析趋势的方式其实很简单，就是寻找什么是未来，考虑供需关系，把握稀缺性。 那趋势是什么呢？除了当前AI时代，美国科技巨头公司之外，在这里我提及几个今天我关注到的趋势。 第一个就是黄金，随着新冠疫情的爆发，全球央行都在拼命的发行货币，救民生，救企业，搞宽松，这种集体性的行为给货币造成贬值的同时，也给黄金带来了巨大的投资机会。在这个动荡的年代，黄金的避险属性的重要性是不言而喻的。除此以外，近些年来各大央行对黄金的需求量在不断增加，但是由于资源的枯竭（根据美国地质调查局发布的数据显示，全世界黄金现有储量大约59000吨，以2023年开采量3000吨来计算，仅够开采19.7年）和开采成本的大幅度上升（因资源型国家通货膨胀，人力电力等成本提高，老矿山资源日渐枯竭，品味下降，且环保成本也不断提高，而新矿山主要集中在政局不稳定的地区），黄金的稀缺性也在不断提升。但是注意黄金当前价格已经来到了4464.51美元/盎司，为千年来历史高点，虽然黄金依旧具有很好的前景，但当前价位较高，需要注意风险。 第二个就是白银，而事实上白银比黄金更为重要。白银与黄金都是贵金属，都具有保值和收藏价值，但除此以外，白银的工业属性更为明显：在很多高科技行业，银的用途非常广泛。几乎每台计算机，手机，汽车，家电都需银，发展新能源（如太阳能，新能源电车）都需要大量白银，工业需求在猛增，但是同样由于资源逐渐枯竭，矿石品味降低，开采难度加大，开采成本上升等因素，白银的缺口逐渐扩大，这种严重的供不应求的局面，使得白银的上涨成为几乎必然的趋势，而且预计上涨幅度会远大于黄金。 第三个就是电。曾经的石油有多重要，未来的电能就有多重要。AI算力需要大量电能，新能源汽车、加密货币都需要大量电能。今年5月我在墨尔本旅行时发现，大量的市区内的免费Tram上都写着：”The future is electric”。 当前发电的主要方式包括：火力发电，水力发电，风力发电，太阳能发电，天然气发电和核能发电。火力(煤炭)发电是传统的主要电力来源，成本低，稳定性高，但污染严重，是明确要被淘汰的；水力发电有成本低的优势，但近些年极端天气频发，稳定性不足；风力发电、太阳能发电等可再生能源是清洁能源，但由于间歇性和波动性，发电不稳定、不可控，难以满足人工智能时代对稳定的电力供应的需求，储能技术是解决间歇性问题的关键，但成本高昂，市场化条件欠缺，限制了大规模应用，而且风力发电、太阳能发电的推广依赖财政补贴，也增加了不稳定性；天然气发电有一个重要前提，那就是拥有稳定可靠的天然气来源；对天然气相对匮乏、依赖进口的国家来说，会面临价格波动的风险。因此核电是人工智能时代最可靠的电力来源之一，具有稳定、高效、零碳排放等优势，是解决能源转型过程中稳定供电问题的关键，正逐步成为电力缺口的核心填补者。综上所述，美股中具有核电，天然气资源，区域垄断，股息派发稳定且政策支持的公司有着巨大的投资机会。此外，核能发点需要大量的铀，核电的飞速发展意味巨大的铀的需求，但是从全球来说，铀的供应不能满足需求，供应缺口逐渐增大，因此相关龙头企业值得关注。 墨尔本市区随处可见的Tram，拍摄于Melbourne, Australia, 2025年5月4日 总结像这样确定性的大趋势还有很多，2026年还需要不断学习，提升自己的认知水平。","link":"/report_2025.html"},{"title":"About Me","text":"Hello","link":"/about/about.html"}]}