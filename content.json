{"posts":[{"title":"Markov Chains","text":"IntroductionLet $(\\Omega,\\mathcal{F})$ be a measurable space, $P:\\Omega\\times \\mathcal{F}\\to [0,1]$ be a transition kernel, that is, for every $x\\in \\Omega$, $P(x,\\cdot)$ is a probability measure on $\\mathcal{F}$; for every $A\\in \\mathcal{F}$, $x\\mapsto P(x,A)$ is measurable. And we say the triple $(\\Omega,\\mathcal F,P)$ is a Markov scheme. Fix an initial distribution $\\mu_0$ on $(\\Omega,\\mathcal F)$. By the Kolmogorov consistency theorem, there exists a unique probability measure $\\mathbb{P}$ on the product space $(\\Omega^{\\mathbb N_0},\\mathcal F^{\\otimes\\mathbb N_0})$ such that for the coordinate process $X_k$,$$\\mathbb P(X_0\\in A_0,\\dots,X_n\\in A_n)=\\int_{A_0}\\mu_0(dx_0)\\int_{A_1}P(x_0,dx_1)\\cdots\\int_{A_n}P(x_{n-1},dx_n),\\qquad A_0,\\dots,A_n\\in\\mathcal F.$$ Equivalently: $X_0\\sim\\mu_0$; for every $k\\ge 0$ and $A\\in\\mathcal F$, $$\\mathbb P(X_{k+1}\\in A\\mid X_0,\\dots,X_k)=\\mathbb P(X_{k+1}\\in A\\mid X_k)\\quad \\text{a.s.} \\qquad \\text{(Markov property)}.$$ A probability measure $\\pi$ on $(\\Omega,\\mathcal F)$ is invariant (stationary) for $P$ if$$(\\pi P)(A):=\\int_\\Omega \\pi(dx)\\ P(x,A) =\\pi(A).$$Equivalently, if $X_0\\sim\\pi$, then $X_k\\sim\\pi$ for every $k\\ge 1.$","link":"/2025/12/18/Markov_Chain_1/"},{"title":"Between Sampling and Optimization","text":"Introduction​ Let $p$ be a positive integer and $f:\\mathbb{R}^p\\to \\mathbb{R}$ be a measurable function such that$$\\int_{\\mathbb{R}^p} e^{-f(x)} dx&lt;+\\infty.$$In various applications, one is faced with the problem of finding the minimum point of $f$ or computing the average with respect to the probability density$$\\pi(x) = \\dfrac{e^{-f(x)}}{\\int_{\\mathbb{R}^p} e^{-f(u)}du}.$$ In other words, one often looks for approximating the values $ x^{*} $ and $ \\bar x $ defined as $$x^{*} \\in \\arg\\min_{x\\in \\mathbb{R}^p} f(x), \\quad \\bar x = \\int_{\\mathbb{R}^p} x \\pi(x) dx.$$ AssumptionAssumption 1. We assume $f$ is strongly convex with Lipschitz continuous gradient. That is, we assume that there exist two positive constants $m$ and $M$ such that for all $x,y\\in \\mathbb{R}^p$,$$f(y)-f(x)-\\nabla f(x)^T (y-x)\\ge \\frac{m}{2}||y-x||_2^2,$$and$$||\\nabla f(x)-\\nabla f(y)||_2\\le M ||x-y||_2.$$ Langevin Monte Carlo (LMC) Algorithm​ Starting from an initial point $x^{(0)}\\in \\mathbb{R}^p$ that maybe deterministic or random, the iterations of the algorithm are defined by the update rule$$x^{(k+1,h)} = x^{(k,h)}-h\\nabla f(x^{(k,h)})+\\sqrt{2h}\\ \\xi^{(k+1)};\\quad k=0,1,2,\\cdots \\tag{LMC}$$where $h&gt;0$ is the tuning parameter, refer to as the step size, and $\\xi^{(1)},\\cdots,\\xi^{(k)},\\cdots$ is a sequence of mutually independent, and independent of $x^{(0)}$, centered Gaussian vectors with covariance matrices equal to identity. Let $\\nu_k$ be the distribution of the $k$-th iterate of the LMC algorithm, that is $x^{(k,h)}\\sim\\nu_k$. Main Idea of LMC Algorithm​ The Markov chain $\\{x^{(k,h)}\\}_{k\\in \\mathbb{N}}$ is the Euler-Maruyama discretization of the following Langevin dynamic SDE:$$dL_t = -\\nabla f(L_t)+\\sqrt{2}dW_t,\\quad t\\ge 0,$$where $\\{W_t;\\ t\\ge 0\\}$ is a $p-$dimensional Brownian motion, $\\{L_t; t\\ge 0\\}$ is known as Langevin diffusion. When $f$ satisfies Assumption 1, the above SDE has a unique strong solution which is a Markov process. ​ By Fokker-Planck Equation, we know $\\{L_t; t\\ge 0\\}$ has $\\pi$ as invariant density, namely if $L_0\\sim \\pi$ then $L_t\\sim \\pi$ for all $t\\ge 0$. ​ Under Assumption 1, when $h$ is small and $k$ is large (so that the product $kh$ is large), the distribution of $x^{(k,h)}$ is close in various metrics to the distribution $\\pi$ with density $\\pi(x)$. So the question is how to quantify this closeness? Wasserstein DistanceDefinition 1. For two measures $\\mu$ and $\\nu$ defined on $(\\mathbb{R}^p,\\mathcal{B}(\\mathbb{R}^p))$, the $2-$Wasserstein distance is defined by$$W_2(\\mu,\\nu) = \\left( \\inf_{\\gamma\\in \\Gamma(\\mu,\\nu)}\\int_{\\mathbb{R}^p\\times \\mathbb{R}^p}||x-y||_2^2d\\gamma(x,y)\\right)^{1/2},$$where the infimum is with respect to all joint distributions $\\gamma$ having $\\mu$ and $\\nu$ as marginal distributions. Here we review some important properties of Wasserstein distance. Proposition 1. For two Dirac measure $\\delta_x$ and $\\delta_y$, we have $$W_2(\\delta_x,\\delta_y) = ||x-y||_2.$$Proposition 2. The infimum in the definition of Wasserstein distance is achievable. That is to say there exists a joint distribution $\\gamma^*\\in \\Gamma(\\mu,\\nu)$ such that $$W_2(\\mu,\\nu) = \\left( \\int_{\\mathbb{R}^p\\times \\mathbb{R}^p}||x-y||_2^2d\\gamma^*(x,y)\\right)^{1/2}.$$ Main Theorem Theorem 1. Assume that $h\\in (0,\\frac{2}{M})$. The following claims hold: (a) If $h\\le \\frac{2}{m+M}$ then $W_2(\\nu_k,\\pi)\\le (1-mh)^k W_2(\\nu_0, \\pi)+ \\frac{M}{m}(5hp/3)^{1/2}.$ (b) If $h\\ge \\frac{2}{m+M}$ then $W_2(\\nu_k,\\pi)\\le (Mh-1)^k W_2(\\nu_0, \\pi)+ \\frac{Mh}{2-Mh}(5hp/3)^{1/2}.$ Relation with OptimizationThe function $f(x)$ and the function $f_\\tau(x):=f(x)/\\tau$ have the same minimizer $x^{*}$, whatever the real number $\\tau&gt;0$. If we define the density function $\\pi_\\tau(x)\\propto \\exp(-f_\\tau(x))$, then the average value$$\\bar x_\\tau = \\int_{\\mathbb{R}^p} x \\pi_\\tau (x)dx$$tends to the minimizer $x^* $ when $\\tau\\to 0$. Furthermore, the distribution $\\pi_{\\tau}$ tends to the Dirac measure $\\delta_{x^{*}}$.","link":"/2025/10/09/LMC_GD/"},{"title":"Introduction to Diffusion Model","text":"Diffusion Model","link":"/2025/10/24/diffusion/"},{"title":"Introduction to Sampling","text":"There are mainly two settings of sampling problem.","link":"/2025/10/20/sampling_introduction/"},{"title":"Introduction to Flow Matching","text":"In generative modeling, we are given a collection of training samples $\\{x_i\\}_{i=1}^N$ and wish to generate new samples from the underlying target distribution $\\pi$. There are already many established approaches to this problem, including likelihood-based methods, implicit generative models such as GANs, and score-based diffusion models. More recently, the flow matching framework has emerged as another powerful paradigm. In what follows, we introduce the basic ideas of flow matching and explain how works. BackgroundFor a particle initially at position $x_0 \\in \\mathbb{R}^d$ and a (Lipschitz continuous) velocity field $\\{v_t\\}$, there exists a unique trajectory $\\{x_t\\}$ described by $$\\begin{cases}\\begin{split}\\dfrac{d x_t}{dt} &amp;= v_t(x_t),\\quad t\\in [0,1]\\\\\\x_0&amp;=x_0\\end{split}\\end{cases}.\\tag{Flow-ODE}$$The flow $\\Phi$ collects the trajectories corresponding to different initial positions $x_0$ and is defined by $$\\begin{split}\\Phi: [0,1]\\times \\mathbb{R}^d&amp;\\to \\mathbb{R}^d\\\\\\(t,x_0)&amp;\\mapsto \\Phi(t,x_0)=x_t,\\end{split}$$where $x_t$ denotes the solution of (Flow-ODE) at time $t$. If the flow mapping $\\Phi$ is known, then for any initial position $x_0 \\in \\mathbb{R}^d$ we can obtain the terminal position $x_1$ via $x_1 = \\Phi(1,x_0)$. To determine the flow mapping $\\Phi$, it suffices to know the velocity field $\\{v_t\\}_{t \\in [0,1]}$ and to solve the ordinary differential equation (Flow-ODE). Figure 1: A particle moves from $x_0$ to $x_1$ along the velocity field $v_t$. In general, we aim to use the flow mapping $\\Phi$ to transport the initial distribution $\\mu_0$ to the target distribution $\\pi$. Figure 2: Transport the initial distribution $\\mu_0$ to the target distribution $\\pi$ by the flow mapping $\\Phi$ (or the corresponding vector field $v_t$). Let $\\{X_t\\}$ be a stochastic process with $\\operatorname{Law}(X_t)=\\mu_t$ such that$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ a.e. \\\\\\X_0&amp;\\sim \\mu_0\\end{split}\\end{cases},\\quad t\\in [0,1]$$Then we know $(\\mu_t,v_t)$ must satisfies the following continuity equation$$\\partial_t \\mu_t +\\nabla\\cdot (\\mu_tv_t) = 0,$$which means for all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we have$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t(dy)dt=0.\\tag{CE}$$If $\\mu_t$ has density $\\rho_t$ with respect to Lebesgue measure on $\\mathbb{R}^d$, continuity equation can be written as$$\\partial_t \\rho_t +\\nabla\\cdot (\\rho_tv_t) = 0.$$ Note: The ODE formulation$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ \\text{a.e.} \\\\\\X_0 &amp;\\sim \\mu_0\\end{split}\\end{cases}\\qquad t\\in [0,1]$$is the Lagrangian (particle) viewpoint, while the continuity equation$$\\partial_t \\mu_t + \\nabla\\cdot(\\mu_t v_t) = 0$$is the Eulerian (distribution) viewpoint. One can show that the Lagrangian formulation implies the Eulerian one. Conversely, under suitable assumptions, if the continuity equation holds, then there exists a stochastic process $(X_t)_{t\\in[0,1]}$ solving the ODE above. This result is often referred to as the superposition principle (see [1] for a reference). Hence, once we have learned a “good” flow map $\\Phi$, we can sample $X_0$ from the initial distribution $\\mu_0$ (for instance, a Gaussian $N(0, I_d)$), and then obtain$$\\operatorname{Law}(X_1) =\\operatorname{Law}(\\Phi(1, X_0)) =\\mu_1 \\approx \\pi.$$The central question is therefore: how can we learn such a “good” flow map $\\Phi$, or equivalently, how can we design the vector field $\\{v_t\\}$ using only the training data $\\{x_i\\}_{i=1}^N \\stackrel{\\text{i.i.d.}}{\\sim} \\pi$? Flow MatchingThe main idea of flow matching is to approximate the target vector field $v_t$ by a neural network $u_t^{(\\theta)}$. The neural network is trained by minimizing a suitable discrepancy between $u_t^{(\\theta)}$ and an explicitly known conditional vector field $v_t^x$. To make this precise, we first introduce the conditional probability paths $\\mu_t^x$ and the corresponding conditional vector fields $v_t^x$, and then explain how they relate to the marginal probability path $\\mu_t$ and the marginal vector field $v_t$ that we ultimately wish to learn. Conditional Probability Path and Conditional Vector FieldDefinition 1. The conditional probability path is a path of Markov kernel denoted by $\\mu_t^x$ satisfying: (1) For all $t\\in [0,1]$ and $A\\in \\mathcal{B}(\\mathbb{R}^d)$, the mapping $x\\mapsto \\mu_t^x(A)$ is $\\mathcal{B}(\\mathbb{R}^d)$-measurable; (2) For all $t\\in [0,1]$ and $x\\in \\mathbb{R}^d$, $\\mu_t^x(\\cdot)$ is a probability measure on $\\mathbb{R}^d$; (3) For all $x\\in \\mathbb{R}^d$, $\\mu_0^x\\equiv \\mu_0$ and $\\mu_1^x=\\delta_x$. Note: Property (3) above is used to ensure that the marginal probability path$$\\mu_t(A) := \\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d),$$satisfies $\\mu_0 = \\mu_0$ (our prescribed initial distribution) and$$\\mu_1(A) = \\int_{\\mathbb{R}^d} \\delta_x(A)\\ \\pi(dx) = \\int_A \\pi(dx) = \\pi(A), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d),$$which implies that $\\mu_1 = \\pi$. Hence $\\mu_t$ is a probability path interpolating between the initial distribution $\\mu_0$ and the target distribution $\\pi$, which is exactly what we want. In practice, one may choose a sufficiently small $\\sigma_{\\min} &gt; 0$ and set $\\mu_1^x = N(x, \\sigma_{\\min}^2)$, so that in the end $\\mu_1 \\approx \\pi$. Construction of Conditional Probability PathThere are many ways to construct a conditional probability path $\\mu_t^x$ satisfying the conditions in Definition 1. Here, we adopt a simple conditional Gaussian path$$\\mu_t^x = N(m_t^x,(\\sigma_t^x)^2I_d),$$where$$m_t^x = tx\\quad \\text{and}\\quad (\\sigma_t^x)^2 = (1-t)^2\\sigma_0^2+\\sigma_{\\min}^2,$$with $\\sigma_0^2=1-\\sigma_{\\min}^2$. It is easy to see that$$\\mu_0^x = N(0,I_d)\\quad \\text{and}\\quad \\mu_1^x = N(x,\\sigma_{\\min}^2I_d)\\approx \\delta_x.$$Naturally, we hope our trajectory is$$Y_t^x = m_t^x+\\sigma_t^x Z,$$where $Z\\sim N(0,I_d)$ and we have $\\operatorname{Law}(Y_t^x)=\\mu_t^x$. By differentiating $Y_t^x$ with respect to $t$, we obtain$$\\begin{aligned}\\dfrac{d}{dt}Y_t^x &amp;= \\dot m_t^x+\\dot \\sigma_t^x Z\\\\\\&amp;=\\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (Y_t^x-m_t^x),\\end{aligned}$$where $\\dot m_t^x = \\dfrac{d}{dt} m_t^x$ and $\\dot \\sigma_t^x = \\dfrac{d}{dt} \\sigma_t^x$. Hence, we can choose the conditional vector field$$v_t^x(y):= \\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (y-m_t^x).$$Then we have$$\\begin{cases}\\dfrac{d}{dt}Y_t^x = v_t^x(Y_t^x),\\ \\operatorname{Law}(Y_t^x)=\\mu_t^x\\\\\\Y_0^x\\sim \\mu_0^x\\end{cases},\\quad t\\in [0,1].$$Therefore, $(\\mu_t^x, v_t^x)$ satisfies the continuity equation: for all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we have$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t^x(dy)dt=0.\\tag{CE-conditional}$$ Summary We construct the conditional probability path$$\\mu_t^x = N(m_t^x,(\\sigma_t^x)^2I_d),$$where$$m_t^x = tx\\quad \\text{and}\\quad (\\sigma_t^x)^2 = (1-t)^2\\sigma_0^2+\\sigma_{\\min}^2,$$with $\\sigma_0^2=1-\\sigma_{\\min}^2$ and it satisfies$$\\mu_0^x = N(0,I_d)\\quad \\text{and}\\quad \\mu_1^x = N(x,\\sigma_{\\min}^2I_d)\\approx \\delta_x.$$Then we construct the conditional vector field$$v_t^x(y):= \\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (y-m_t^x).$$And then $(\\mu_t^x, v_t^x)$ satisfies the continuity equation: for all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we have$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t^x(dy)dt=0.\\tag{CE-conditional}$$ Marginal Probability Path and Marginal Vector FieldWe define the marginal probability path $\\mu_t$ by$$\\mu_t(A) := \\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d).$$We have $\\mu_t$ start at our initial distribution $\\mu_0$ and end by$$\\mu_1\\approx \\pi.$$What’s more, we have the following lemma. Lemma 1. For $\\pi-$a.e. $x$, we have $\\mu_t^x\\ll \\mu_t$. Proof : If $\\mu_t(A)=0$, then$$\\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx)=0.$$Since $\\mu_t^x(A)\\ge 0$, we have for $\\pi-$a.e. $x$, $\\mu_t^x(A)=0$. Hence, for $\\pi-$a.e. $x$, we have $\\mu_t^x\\ll \\mu_t$. By Lemma 1, for $\\pi-$a.e. $x$, the Radon-Nikodym derivative$$\\dfrac{d\\mu_t^x}{d\\mu_t}$$exists. Then we can define the marginal vector field as$$v_t(y):= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\pi(dx).$$Note: To some extent, $v_t$ is a weighted average of $v_t^x$. Theorem 2. $(\\mu_t, v_t)$ satisfies the continuity equation. Proof : For all $\\varphi\\in C_c^{\\infty}((0,1)\\times \\mathbb{R}^d)$, we need to show that$$I=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t(dy)dt=0.$$In fact, $I=I_1+I_2$, where$$\\begin{aligned}I_1&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\mu_t(dy)dt\\\\\\I_2&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\mu_t(dy)dt.\\end{aligned}$$By using$$\\mu_t(dy) =\\int_{\\mathbb{R}^d} \\mu_t^x(dy)\\ \\pi(dx)$$and$$v_t(y):= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx),$$we have$$\\begin{aligned}I_1&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\ \\mu_t(dy)\\ dt\\\\\\&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;\\xlongequal{\\text{Fubini}}\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\dfrac{\\partial}{\\partial t}\\varphi(t,y)\\ \\mu_t^x(dy)\\ dt\\ \\pi(dx)\\end{aligned}$$and$$\\begin{aligned}I_2&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), \\nabla\\varphi(t,y)\\rangle\\ \\mu_t(dy)\\ dt\\\\\\&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx)\\ \\mu_t(dy)\\ dt\\\\\\&amp;\\xlongequal{\\text{Fubini}}\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\mu_t(dy)\\ dt \\ \\pi(dx)\\\\\\&amp;\\xlongequal{\\text{Chain Rule}}\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\ \\mu_t^x(dy)\\ dt \\ \\pi(dx).\\end{aligned}$$Hence by $(\\mu_t^x, v_t^x)$ satisfies the continuity equation, namely$$\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\mu_t^x(dy)dt=0$$we get$$I=I_1+I_2 =\\int_{\\mathbb{R}^d}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\left[\\dfrac{\\partial}{\\partial t}\\varphi(t,y)+\\langle v_t^x(y), \\nabla\\varphi(t,y)\\rangle\\right]\\ \\mu_t^x(dy)\\ dt\\ \\pi(dx)=0,$$which means $(\\mu_t, v_t)$ satisfies the continuity equation. By Theorem 2, there exists a stochastic process $X_t$ with $\\operatorname{Law}(X_t)=\\mu_t$ such that$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ a.e. \\\\\\X_0&amp;\\sim \\mu_0\\end{split}\\end{cases},\\quad t\\in [0,1]$$And $\\mu_t$ start at our initial distribution $\\mu_0$ and end by$$\\mu_1\\approx \\pi.$$ Summary We construct the marginal probability path and marginal vector field by$$\\begin{aligned}\\mu_t(A) &amp;:= \\int_{\\mathbb{R}^d} \\mu_t^x(A)\\ \\pi(dx), \\quad \\forall A \\in \\mathcal{B}(\\mathbb{R}^d).\\\\\\v_t(y)&amp;:= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\pi(dx).\\end{aligned}$$We have $(\\mu_t, v_t)$ satisfies the continuity equation, which means there exists a stochastic process $X_t$ with $\\operatorname{Law}(X_t)=\\mu_t$ such that$$\\begin{cases}\\begin{split}\\dfrac{d X_t}{dt} &amp;= v_t(X_t),\\ a.e. \\\\\\X_0&amp;\\sim \\mu_0\\end{split}\\end{cases},\\quad t\\in [0,1].$$And $\\mu_t$ start at our initial distribution $\\mu_0$ and end by$$\\mu_1\\approx \\pi.$$ Now we can answer the question about how to train the neural network $u_t^{(\\theta)}$. TrainingTheorem 3. Define the marginal loss $L(\\theta)$ and conditional loss $J(\\theta)$ by$$\\begin{aligned}L(\\theta)&amp;:= \\int_{0}^{1}\\int_{\\mathbb{R}^d}|v_t(y)-u_t^{(\\theta)}(y)|^2\\ \\mu_t(dy)\\ dt\\\\\\J(\\theta)&amp;:= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|v_t^x(y)-u_t^{(\\theta)}(y)|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\end{aligned}$$We have$$L(\\theta) = J(\\theta)+C,$$where $C$ is a constant independent of $\\theta$. Hence,$$\\arg\\min_{\\theta} L(\\theta)=\\arg\\min_{\\theta} J(\\theta).$$Proof : Expand $L(\\theta),\\ J(\\theta)$ as$$L(\\theta) = A_1-2B_1+C_1,$$where$$A_1 = \\int_{0}^{1}\\int_{\\mathbb{R}^d}|v_t(y)|^2\\ \\mu_t(dy)\\ dt,\\ B_1= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t(dy)\\ dt,\\ C_1= \\int_{0}^{1}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t(dy)\\ dt$$and$$J(\\theta) = A_2-2B_2+C_2,$$where$$A_2= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|v_t^x(y)|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt,\\ B_2=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt,\\ C_2= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt.$$By using$$\\mu_t(dy) =\\int_{\\mathbb{R}^d} \\mu_t^x(dy)\\ \\pi(dx)$$and$$v_t(y):= \\int_{\\mathbb{R}^d} v_t^x(y) \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx),$$we have$$\\begin{aligned}C_1 &amp;= \\int_{0}^{1}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t(dy)\\ dt\\\\\\&amp;= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|u_t^{(\\theta)}|^2\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;=C_2\\end{aligned}$$and$$\\begin{aligned}B_1&amp;= \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\langle v_t(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t(dy)\\ dt\\\\\\&amp;=\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\pi(dx)\\ \\mu_t(dy)\\ dt\\\\\\&amp;\\xlongequal{\\text{Fubini}}\\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\dfrac{d\\mu_t^x}{d\\mu_t}(y)\\ \\mu_t(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;\\xlongequal{\\text{Chain Rule}} \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}\\langle v_t^x(y), u_t^{(\\theta)}(y)\\rangle\\ \\mu_t^x(dy)\\ \\pi(dx)\\ dt\\\\\\&amp;=B_2.\\end{aligned}$$Since $A_1$ and $A_2$ are independent of $\\theta$, the desired result follows directly. By Theorem 3, we can sample $\\{t_k\\}_{k=1}^K\\sim U[0,1]$; draw from training dataset $\\{x_i\\}_{i=1}^N$; for all $(t_k, x_i)$, draw $M$ samples $\\{y_m^{(t_k,x_i)}\\}_{m=1}^M\\sim \\mu_t^x=N(m_t^x,(\\sigma_t^x)^xI_d)$. And then train our neural network by$$\\min_\\theta\\quad\\dfrac{1}{KNM}\\sum_{k=1}^K\\sum_{i=1}^N\\sum_{m=1}^M |v_{t_k}^{x_i}(y_m^{(t_k,x_i)})-u_{t_k}^{(\\theta)}(y_m^{(t_k,x_i)})|^2.$$ Summary Our goal is to sample from the target distribution $\\pi$. To this end, we first draw samples (for example $x_0$) from an initial distribution $\\mu_0=N(0,I_d)$ and then apply a trained vector field $u_t^{(\\theta)}$, so that at the terminal time we obtain samples (corresponding $x_1$) distributed (approximately) according to $\\pi$ by solving the following ODE$$\\begin{cases}\\begin{split}\\dfrac{d x_t}{dt} &amp;= u_t^{(\\theta)}(x_t),\\quad t\\in [0,1]\\\\\\x_0&amp;=x_0\\end{split}\\end{cases}$$by numerical method such as the Euler method or the Runge-Kutta method. The way to training the vector field $u_t^{(\\theta)}$​ is by$$\\min_\\theta\\quad\\dfrac{1}{KNM}\\sum_{k=1}^K\\sum_{i=1}^N\\sum_{m=1}^M |v_{t_k}^{x_i}(y_m^{(t_k,x_i)})-u_{t_k}^{(\\theta)}(y_m^{(t_k,x_i)})|^2,$$where $t_k\\sim U[0,1], k=1,\\cdots,K$ and $x_i,\\ i=1,\\cdots,N$ draw from training dataset,$$\\{y_m^{(t_k,x_i)}\\}_{m=1}^M\\sim \\mu_t^x=N(m_t^x,(\\sigma_t^x)^xI_d)$$ and$$v_{t}^{x}(y):= \\dot m_t^x+\\dfrac{\\dot \\sigma_t^x}{\\sigma_t^x} (y-m_t^x)$$with $m_t^x = tx\\quad \\text{and}\\quad (\\sigma_t^x)^2 = (1-t)^2\\sigma_0^2+\\sigma_{\\min}^2$ , $\\sigma_0^2=1-\\sigma_{\\min}^2$. There are mainly three types of errors (terminal error) since $\\mu_1^x=N(x,\\sigma_{\\min}^2I_d)\\approx \\delta_x$, there is an error between $\\mu_1$ and target distribution $\\pi$, but we can control this error by choosing $\\sigma_\\min$ sufficiently small. (discretization error) there is an error when solving the ODE above numerically, but we can control this error by choosing step size $h$ sufficiently small. (flow matching error) there is an error between $u_t^{(\\theta)}$ and true vector field $v_t$, but we can assume the neural network can be trained well enough to make this error small enough. In conclusion: Sampling is as easy as learning the vector field! Reference[1] Ambrosio, Luigi, Nicola Gigli, and Giuseppe Savaré. Gradient flows: in metric spaces and in the space of probability measures. Basel: Birkhäuser Basel, 2005. [2] Lipman, Yaron, et al. “Flow matching for generative modeling.” arXiv preprint arXiv:2210.02747 (2022). [3] Kerrigan, Gavin, Giosue Migliorini, and Padhraic Smyth. “Functional flow matching.” arXiv preprint arXiv:2305.17209 (2023).","link":"/2025/11/27/flow_matching/"},{"title":"Hello Everyone","text":"Hello everyone! Welcome to my blog! I’ll be sharing my journey as a PhD student at the Academy of Mathematics and Systems Sciences, Chinese Academy of Sciences. This blog isn’t just about my math research – I’ll also explore topics like economics, finance, and anything else that sparks my interest! If you have any questions or just want to reach out, feel free to email me at wangtuo1020@outlook.com.","link":"/2025/09/10/hello/"},{"title":"Analogy between Sampling and Optimization","text":"Analogy between Sampling and Optimization","link":"/2025/09/26/sampling_optimization/"},{"title":"《全球视野下的投资机会》（第一章读书笔记）","text":"今天是感恩节，因此我想先用本书的作者，时寒冰先生说过的一句话开头： 感恩已经得到的，不要为没有得到的焦虑 第一章 高盈利的源头抓住财富的密码：顺势而为，正确的时间将钱放在正确的市场小钱是辛苦挣来的，大钱则是靠超前的眼光投资赚得的。然而有的人投资获得了巨大的成功，而有的人却穷其一生，除了累累伤痕，心力交瘁，一无所获，原因可以归纳为一个字：“势”。 所谓“势”，就是资本、资源、人口等流动的方向。 中国经济的真正腾飞始于2001年：中国加入世界贸易组织（WTO），全世界资本开始流入中国。 中国本应借助这种经济高速增长的势头，大力发展高端制造业，全面提升中国的科技水平和制造业水平，但房地产的过度投机犹如黑洞，将不计其数的宝贵资源吸入其中，在一定程度上制约了中国的产业技术升级。这也改变了大趋势。 2018年中美贸易战开始，逆全球化浪潮逐渐兴起，逐渐与欧美等发达国家脱钩断链。高端产业回流欧美日等发达国家和地区，低端产业向东南亚、墨西哥等发达国家转移。 2020年的新冠疫情强化了这一趋势。印度、日本等国股市持续大幅度上涨，但日本的制造业体系更为完善，供应链也极为完整，而且在技术、劳动力等方面有明显的优势，因而日本的重要性凸显，相应的日本的股市和楼市得到了强有力的支撑。 资本流入之地，无论是股市还是楼市，都容易上涨。而资本流出之地，无论是股市还是楼市，都容易下跌。 从行业角度看，资本流动的方向同样是具有决定性的主导力量。 人工智能刚进入初始阶段，未来还有很长一段路要走。2022年底后，AI飞速发展，使得人类从石油驱动经济发展时代逐步步入电力驱动经济发展时代。在过去石油有多重要，未来电力就有多重要。 机器人的发展尤其值得重视。制造机器人的材料需要靓号得机械性能，物理性能和化学性能，因此那些质量轻、强度硬度高、耐磨损、耐腐蚀的材料需求极大，例如PEEK、镁合金、钛合金、铝合金、碳纤维、汝铁硼磁材等。 只有在正确的时间将钱放在正确的市场中才能赚钱并且赚大钱。 正确的市场，就是只要选对品种或者选对企业，哪怕有剧烈的调整，也能很快修复，并持续给你带来可观的投资回报的市场。 错误的市场，就是这个市场已经经过漫长的时间检验，它除了吞噬你的财富或者本钱以外，不能给你带来任何像样的回报。 不要用侥幸和幻想美化现实的残酷，要想获取财富，必须战胜幻想。 紧抓稀缺性物以稀为贵，以稀缺性为目标，是获取高盈利的捷径，但必须考虑时间因素，时间是成就、强化稀缺性的帮手，同时也是摧毁、击败稀缺性的利器。 投资上的稀缺性是指：在某个时间段内（时间长短可由稀缺性的强度而定），某种商品的需求稳定或增长，而供应无法同步增长甚至还可能减少的特性，并且，这种商品在某个阶段内缺乏充分的替代商品，从而导致该商品的供给在该时间段内无法满足需求（消费需求与投资需求）。 供给有限 缺少替代商品或者替代商品不足 需求稳定或增长 强调某个时间段内 稀缺性的分类： 地域稀缺性：某种商品只有这个地方有，而别的地方没有，那么这种稀缺性从空间角度看就是无可替代的。例如茅台。 技术稀缺性：带有新明的垄断特色。例如：英伟达、微软、谷歌等公司，反例如英特尔。技术不仅制造稀缺性也摧毁稀缺性，例如钻石。 不可再生稀缺性：指这种资源原本就很少，而且随着人们的开采、使用会越来越少。但是某段时间内，供应的增长会摧毁稀缺性。例如铟、稀土、可可等。 库存增加，意味着稀缺性的基础在消费降级阶段非常容易坍塌，要顺势而为，及时调整。 稀缺性不仅仅适用于投资，也同样适用于做实业和做人。在人心冷漠的时候，用良心做事所具有的稀缺性，就是最大的号召力，会带来好的回报。 与确定性趋势同行对普通人来说，判断趋势只需要关注 消费、就业和人口。 消费是最直接反应经济现状和未来前景的指标：当一个国家的人满世界抢购奢侈品的时候，这个国家处于明确的上升周期，经济增长势头强劲，房价也会因为获得强大的支持而猛烈上涨。当消费不断降级，人们对商品价格斤斤计较，甚至生活必需品的消费都开始缩减的时候，这说明整个经济处于收缩阶段，此时房价，股市，汇率等承受巨大压力，投资容易亏损。 人口也是判断投资趋势时非常重要的一个因素：一切经济活动归根结底围绕着人进行，生产的东西要卖给人消费，建造的房子要卖给人住。人口如果是增长的，经济上行的动力就更足，反之亦然。历年全国小学数量与招生人数是研究人口变化的一个非常重要的前瞻性指标。由于人口惯性，总人口的萎缩会滞后于出生人口的萎缩，因而不能及时反映人口衰减的严峻性以及其对经济社会的深刻影响。如果只按目前这种力度鼓励生育，中国毫无疑问将在几十年内成为老龄化程度和人口萎缩最严重的国家之一。人口的趋势一旦转变，就很难逆转。人口的变化是房价的一个根本性影响因素。 人口的下降，让房地产的供应显而易见地过剩，而这种趋势会日益明显。因此，依赖房地产拉动经济增长的路子走不通了，必须改变；需要采用以科技创新促进经济增长，以民富路线刺激消费、拉动经济增长的高质量发展模式。 很多人做投资容易犯一个错误，那就是他们总是根据现实的情况做决策。其实，投资交易的是未来，确切地说，应该基于对未来的判断在当下做交易。房地产投资尤其如此。年轻人按揭买房，抵押的并不是现在，而是自己未来几十年可能实现的收入。这是基于未来希望而在当下交易的行为。房地产产业链的各个环节，都是围绕着最核心的群体–年轻群体进行的。只要经济发展只要就业机会好，希望就在。希望在，房地产行业的暴利就能维持。反之，这种交易就会停止。所以，判断房价的走势非常简单，看看年轻群体对未来的希望和激情，看他们处在什么样的状态之下，就一目了然了，从长期趋势来看，人口是增长还是下降(决定需求)，经济是增长还是衰退(决定购买力)，房地产供应是增长还是下降(决定供给)，是决定房价涨跌的关键，也是我们判断未来房价走势的关键。其中，人口因素尤其重要。 固有观念是投资者的敌人，也是投资者最大的心魔之一。例如即便是古人基于自身经验所说的“一铺养三代”的商铺，在电子商务深人每个角落的情况下，其价值也在发生着巨变。电子商务的高速发展蚕食了商铺的价值，让商铺的投资价值变得越来越弱。 想获取高额利润，规避风险，我们做投资决策时必须足够迅速和果断。天下武功无坚不摧，唯快不破。当你发现一个别人没有意识到的好的商机时，应该迅速行动。等别人意识到，想追上来，而你因缺乏独家技术从而无法享有垄断优势的时候，你就要果断将机会转让出去。 因为，在中国投资的特点就是，人多、机会少、资源少、市场不足，尤其是与发达国家的市场“脱钩”之后，国内市场的争夺变得更加激烈。无论哪个领域，只要刚开始赚钱，人们就会一窝蜂地冲上去，用不了多久就会供应过剩，投资者只有赶在供应过剩之前出手才能卖出好价钱，才能体面而安稳地退出。适时退出，也是优秀投资的一个组成部分。 有的时候，某些领域看似风险很大，却需要投资者坚定地往前走。比如，发达国家市场与中国的“脱钩”，对很多行业来说是显而易见的利空影响，但对芯片行业来说却是为数不多的例外之一。当美国对中国的芯片产业一而再、再而三地进行制裁、打压的时候会产生一种反作用力，倒逼中国国产芯片产业发展。虽然在研制高端芯片方面还有很长的路要走，但对于中高端芯片，几乎可以说，这一领域以后就是中国的天下了。这是头部国产芯片的历史性发展机遇。“脱钩”使中国芯片产业高速发展。 全球市场是连通着的。基于同样的规律，中国严厉管控和限制战市场中的相关企业则是重大利多略稀缺矿产资源的出口，对美国资本支持。比如，中国严厉管控锑的出，美国锑业公司 (United States Antimony Corporation，美股代码: UAMY)、珀佩图阿资源公司(Perpetua Resources，又名加拿大金锑矿业公司，美股代码: PPTA) 的股价就获得了强大的支撑力量，因此持续上涨。中国管控稀土的出口，美国稀土类企业的股价就会大幅上涨。比如，致力于建立一个垂直整合的美国国内稀土元素磁体生产供应链的公司–美国稀土有限责任公司(USA Rare Earth，美股代码: USAR)，以及美国最大的稀土矿公司，同时也是美国唯一一家全产业链一体化的稀土生产商–MP材料公司(MP Materials，美股代码: MP)，它们的股票就非常容易受到资金的青睐。 投资者如果停留在过去，就看不到趋势的演变。仅根据过去的经验做投资是危险的。人可以重视经验，但必须往前看，不能被过去的经验束缚住。 很多投资品种的趋势是变化着的。在美国，拜登政府时期，大力鼓励发展新能源，新能源板块走势强劲;而在“特朗普 2.0”时期，美国政府的政策是大力鼓励发展传统能源对新能源的发展则充满了抵触和排斥倾向。但是，这种极端政策的骤然转换，实际上也带来了一些好的、长远的投资机会。比如，充电桩类公司的股票。美国有两家具有代表性的充电服务公司，Blink Charging Co.(美股代码: BLNK) 和ChargePoint Holdings Inc.(美股代码: CHPT)。在拜登政府时期，Blink Charging Co.的股价曾经涨到 64.5 美元的历史高位;而在“特朗普2.0”时期，它的股价跌到了1美元以下的位置。同样地，ChargePoint Holdings Inc.的股价，在拜登政府时期达到过49.48美元的历史高点;而在“特朗普2.0”时期，也跌到了1美元以下的位置。特朗普政府的打压，让人们忘记了新能源汽车依然是未来的大势所趋。看一下现在满大街的加油站，我们就能知道，未来，取代这些加油站的，将是一个个的充电站。因此，特朗普政府对新能源的嫌弃和打压实际上为投资者做长远投资带来了一次好机会。未来，当美国一位青睐新能源的总统走马上任时，这些跌人谷底的充电服务类公司恐怕又会生机勃勃，只不过我们恐怕再也看不到如此低的股价了。当然，前提是这些公司能活着度过“冬天”最暗淡和痛苦的阶段。 我们有限的资金，要永远投在有生命力、有价值的领域和品种上。随着时间的流逝，这些品种的价值更加凸显。也许，过去人们曾经忽略它们，但在接下来的这个经济大周期，它们必将大放异彩。 市场的不确定性越高，蕴含的风险越大。人们往往只看到可能的收益而忽略风险，这样的结果往往很悲惨。 追求确定性盈利，在确定性高的时间节点人手最具确定性的品种这是获取高收益的非常重要的保障。 好眼光需要建立在空间思维的基础之上。所谓空间思维也称“多元思维”、“全方位思维”、“整体思维”或“多维型思维”，是指跳出点、线,面的限制，从上下左右、四面八方去思考问题的思维方式。很多人拥有非黑即白的简单思维习惯，缺乏空间思维能力。越是在自媒体的碎片化信息中流连忘返的人，越缺乏空间思维能力，目光越短浅，而且这种短浅往往是难以改变的。 一个心怀感恩的人，要比一个心中充满仇恨和暴戾之气的人，具有更敏锐的眼光和更聪明的大脑。作为一个趋势分析者，你要想有独到的眼光，看得更远、更透彻，就必须摆脱非黑即白的思维方式，培养自己的空间思维能力。作为一个投资者，你只有摆脱固有的种种局限，让思维彻底解放开来，才能获得洞悉世界、发现好机会所带来的巨大快感。 基本的逻辑思维能力可以帮助我们剔除无用的东西，留下最有价值的，让趋势的推导有依据、有章法，而且，逻辑本身就带有纠错的功能让我们更容易确定趋势的方向。分析趋势，寻找好的投资机会，是一项系统的工程。很多时候，我们需要最大限度地去除感情因素，站在利益相关方的角度去思考、去理，找出各个利益相关方最有可能做出的选择。比较这些选择对趋势可能产生的综合影响，我们才能精准判断趋势的方向。","link":"/2025/11/27/global_investment/"}],"tags":[{"name":"Sampling","slug":"Sampling","link":"/tags/Sampling/"},{"name":"Stochastic Process","slug":"Stochastic-Process","link":"/tags/Stochastic-Process/"},{"name":"Optimization","slug":"Optimization","link":"/tags/Optimization/"},{"name":"Paper Reading","slug":"Paper-Reading","link":"/tags/Paper-Reading/"},{"name":"Diffusion Model","slug":"Diffusion-Model","link":"/tags/Diffusion-Model/"},{"name":"Generative Modeling","slug":"Generative-Modeling","link":"/tags/Generative-Modeling/"},{"name":"Investment","slug":"Investment","link":"/tags/Investment/"},{"name":"Book Reading","slug":"Book-Reading","link":"/tags/Book-Reading/"}],"categories":[{"name":"Sampling","slug":"Sampling","link":"/categories/Sampling/"},{"name":"Investment","slug":"Investment","link":"/categories/Investment/"}],"pages":[{"title":"About Me","text":"Hello","link":"/about.html"},{"title":"An Introduction to Sampling","text":"Sampling algorithms provide efficient ways to generate samples from complex probability distributions. They are widely applied in areas such as Bayesian inference, optimization, physics, and machine learning, making them essential tools for connecting theory with practical data analysis. The Goal of SamplingThe goal of sampling is to generate random variable $X\\sim \\pi$ from a target distribution $\\pi$, typically known up to a normalization constant$$\\pi \\propto e^{-V(x)}$$","link":"/sampling_introduction.html"},{"title":"What is Economy?","text":"Three Main Problems for Economy How People Make Decisions How People Interact How the Economy as a Whole Works Ten Principles of EconomyHow People Make Decisions People face tradeoffs. The cost of something is what you give up to get it. Rational people think at the margin. People respond to incentives. How People Interact Trade can make everyone better off. Markets are usually a good way to organize economic activity. Governments can sometimes improve market outcomes. How the Economy as a Whole Works The standard of living depends on a country’s production. Prices rise when the government prints too much money. Society faces a short-run tradeoff between inflation and unempolyment. 1. People face tradeoffsThere is no such thing as a free lunch! To get one thing, we usually have to give up another thing. 2. The cost of something is what you give up to get itThe opportunity cost of an item is what you give up to obtain that item. 3. Rational people think at the marginMarginal changes are small, incremental adjustments to an existing plan of action. 4. People respond to incentivesMarginal changes in costs or benefits motivate people to respond. The decision to choose one alternative over another occurs when that alternative’s marginal benefits exceed its marginal costs! 5. Trade can make everyone better offPeople gain from their ability to trade with one another. Competition results in gains from trading. Trade allows people to specialize in what they do best.","link":"/economy_what_is_economy.html"},{"title":"About Me","text":"Hello","link":"/about/about.html"}]}